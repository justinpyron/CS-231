{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transform=None,\n",
    "                 preload=False,\n",
    "                 subset=None):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "            - subset: the number of examples from each class to include in dataset\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        for i in range(10):\n",
    "            filenames = glob.glob(osp.join(root, str(i), '*.png'))\n",
    "            \n",
    "            if subset is not None:\n",
    "                assert type(subset) is int, 'argument subset must be of type int'\n",
    "                filenames = filenames[:subset]\n",
    "            \n",
    "            for fn in filenames:\n",
    "                self.filenames.append((fn, i)) # (filename, label) pair\n",
    "                \n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn, label in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the MNIST dataset. \n",
    "# transforms.ToTensor() automatically converts PIL images to\n",
    "# torch tensors with range [0, 1]\n",
    "trainset = MNIST(\n",
    "    root='mnist_png/training',\n",
    "    preload=True, \n",
    "    transform=transforms.ToTensor(),\n",
    "    subset = 1000\n",
    ")\n",
    "\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "# load the testset\n",
    "testset = MNIST(\n",
    "    root='mnist_png/testing',\n",
    "    preload=True, \n",
    "    transform=transforms.ToTensor(),\n",
    "    subset = 200\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(9) tensor(5) tensor(7) tensor(7) tensor(3) tensor(3) tensor(9) tensor(9) tensor(9) tensor(9) tensor(5) tensor(4) tensor(6) tensor(4) tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsXXdYFNfbfRdsgAiIKBYEW+wlGhVi\nwxi70RgRezTWGDUqlmiMgiWaqJjYe2+fREzEEivFBlYEuwhSFAFR6lJn5nx/6M5vh11wywwkZM7z\nnIdlyntn7tw5c+v7KgCQDBkyZKhgUtIXIEOGjH8WZFGQIUOGALIoyJAhQwBZFGTIkCGALAoyZMgQ\nQBYFGTJkCCCZKCgUil4KheKJQqF4plAo5kmVjgwZMsSFQop5CgqFwpSInhJRdyJ6QUQ3iWgYgIei\nJyZDhgxRIVVNoR0RPQMQBSCPiP6PiAZIlJYMGTJERBmJ7NYkoji1/18QUfvCDlYoFPK0ShkypEcy\nALsPHSSVKCi0bBO8+AqFYiIRTZQofRkyZGgiRpeDpBKFF0TkoPZ/LSKKVz8AwDYi2kYk1xRkyPgn\nQao+hZtE1EChUNRRKBTliGgoEflJlJYMGTJEhCQ1BQCMQqGYSkRniciUiHYBeCBFWjJkyBAXks1T\nAHAawEcA6gH4WYo0cnNzKScnRwrTJQovLy8CQADI1dW1pC/nX4GaNWvS4cOHiWEYAkDPnj0jKysr\n0eyvXbuWNm3aRLdu3SIAxHGcVu7YsYM6d+4sWrolAlXhK0nSu05IvckwDBiGwYwZMww6/59Kdbi6\nupb49fwb6O3tDY7jBDx58iQqVqxotO2GDRsiJycHLMvqxOTkZHz66aclnidaeEun97GkBcEYUcjP\nzwfHcdi+fXuxZKqDgwPWrVuHpKQkAMBvv/0mehpeXl4AAC8vr5IuQP8aduzYEREREeA4DitXrkTn\nzp0RHR0NjuNQq1YtUdI4dOgQEhIScOfOHXh4eKBq1aowNzfn6eHhgdu3b/PCcO7cuWK7f1dXV3h5\nefEs4kNS+kVB9UUoDlGoVasWDh8+LPgi3L17F5aWlqI+3OIUBHNzc/zyyy+Ii4sDAKxbtw79+vVD\n5cqVMWbMGBw6dAiPHz8WPV0zMzPUrVsXI0aMwKNHj8CyLE6ePGmwvQEDBuD27dv4+eefYWJigjFj\nxiAjI0NUUVCVgaL2Dxs2jC8biYmJkj8/1QdEGwo5RxYFsahQKHDgwAGNaiLDMGjSpIlo6XzggYpG\nKysrbNy4EeHh4TpVh41Nz9TUFO7u7vjrr79w/PhxXLlyhW/6qXj37l3R7s/DwwOHDx/GtGnTUKZM\nGcnzU0Vvb28+zzw9PSVJo6AQBAQE8DUEFeSaAschJSUF7du3l+xhr1u3TuvL4uPjI8nDlrrwLl26\nlL+HtLQ0hISE8GQYRqN9bGx6kyZN4l9+lZgyDIOQkBA8ffoUDMNg06ZNot3frFmzoFQqJc9HdXbo\n0AGvX78Gy7J49eoVKleuLKp99fIREBCg8eLr2Oz874hCSEgIHBwcJHnY48ePR05ODqKjo/HTTz/h\nyZMn/AszcOBA0dJRf+BSFdwqVapg5syZyMrK4u9h8ODBgmMmT54sEIVff/3V4PSGDBmCiIgIZGdn\n80Iwf/58jBw5Eubm5nBzc0Nubi4YhkGNGjVEuUd3d3cwDAOO4yTLRwsLC3Tt2hXz5s3jmZaWBpZl\noVQqsWDBAlHScXV1RUBAgEbNoOBx6oIhi4KEzQdzc3OsXr0a2dnZYFkW06ZNQ82aNQUvjBSiIFV/\nQqdOneDv7y+4/sDAQI3jlixZwu+Pj49H3bp1DUrPysoKUVFRYBgGN27cwNWrV7F//37BMTt27ADD\nMEhMTISNjY3Rz2vYsGF8bWTNmjWS5GPlypURFxenteaYkJCAli1bipJOQTEorFwUbE7IoiCRKDRo\n0AABAQH8w87Ly0PlypWxbds2yURBvRCIXZCtrKxw584dwbVfv34dXbt21Tj25MmT/DFubm4Gp7lz\n504wDINvvvkGZcuW1dh/4MAB5OXlISwsDPXr1zf6Hjdt2sSXh8zMTOzZsweVKlUSPS9r1KiBnJwc\nnnl5eXx+paSkYNKkSTAxMRGtLGhrKhCRRj+C6tgP2C7dotCiRQtJRKFZs2aCl+fx48c4ceKE1k7G\nXbt2wdbWVrS0C1YXxWpKqMQsOTkZo0eP1tjfvn17JCcn8/f23Xffif4yqdi9e3c8f/4cDMPgp59+\nMrgmUpDVqlVDo0aNYGJigho1aqBr164IDg4Gx3E4dOiQqM9JG2vXro1bt27xebhhwwaD7KhDNbxY\nmAB4eXkJyosOc1pKtyh069atWERBGxMTE+Hu7i5J4VINS6rD2AlMLi4u+Prrr2Fvb6+xb+HChUhI\nSODvLTQ0FA0bNpTs5bl69SoYhsGJEyfg5OQkWTpEhHLlymH8+PGIjo5GYmIiOnfuLGl6ZcqU4T8g\nSqUSU6ZM0dtGUVAJgbbjdfyAyKJgCHURhZ49e0pauArWGKSct6BeQ2BZVmtVX0yqalnFOeOvXr16\nuHnzJtLS0iQXhhYtWuDFixdgWRZv3rxBzZo19TpfW42gsI+COnS0L4uCITQ1NcXx48eRnp6O3Nxc\nJCQkwM/Pj39pLly4AFNT02IpzCphKC5RWLJkidHt4aJYvXp1AMD169clr84XZPny5RESEoLIyEjJ\nha9v3758X8O3334rWbn4kGhooSwKxrBx48bo0aMHiN51PKo6kqQa+ixI9WaEVKJgZmbGC8LTp09h\nZWUl2f1UrFgRt27dQnx8PKpVq1YseViQzZo1A8dx2LNnj+RpLViwACzLIj8/H926dZOkXOgpCKDS\nLgpOTk7FNqPx/v37YFkW/v7+xVaA9Rh7Npj29vZgWRYRERGoU6eOZPdStmxZHDt2DAzDSNYXowsr\nVKiAx48fIywsTPK0ateuzQvuqFGjRLEpwoeidIsC0f+GJP38/CT7yn366afIzMzErVu3RFlxV9QD\n1/bwpZrMZGZmhqtXr4JlWcyePVuy+6pQoQIGDhwIhmGQlZUlSRoNGzaEs7NzofubNGmCiRMnIjw8\nHBzH4fLly6KlrVoP8fnnn/McP348/yERSxT0HGUojP8dUeA4TuuYu7GsW7cuP3V17969khRoov+N\nOav+V4cU6VlaWuLy5ctgWRbe3t6oXr26ZPc2c+ZMMAyDjIwMo2ZHFkVfX1/MnDlTsK1p06ZYuHAh\nwsLC+BmOHMfh6dOnBg2Durq6YtasWTh8+DCePn3KMzExEU+fPi20UzooKMioRXMGzEUoiqVfFFiW\nBcdxiImJQYsWLUQvbKNGjeIfbuvWrSV7cVTjzerjzga0F3WijY0NLl68KNpipw/x2rVrYBhG1HUi\nBRkeHo60tDScOnUKL168QHx8PHJycgQfjbt372LdunUGT2j6+++/dVo8ppoPcuXKFXh6eholCAE6\nzmrUg6VfFKSkhYUF/5DT09NL/HrEoL29PaKiovj7un37tmRpNWnShF/vUPArLlM3qn8gRLIpi4Ix\nNDExwaJFi8CyLMaNG1fi1yMGe/XqxQtCfn6+UdOYP8SHDx+CYRicP38e5cqVK/F7l0kgWRRkFqS6\nKHz11VeSpdOsWTN+ZeScOXNK/L5l8tRJFCSJJakv5LgPMmQUC24D+ORDB8mh6GXIkCGALAoyZMgQ\nQBYFGTJkCCCLggwZMgSQRUGGDBkCyKIgQxJUqFCBdu/eTbGxsSV9KTL0hCwK/0F89913lJCQwMc/\nfPHiBS1cuJAaN24sWhqWlpY0evRosrW1pY8++kg0u7rCxcWFYmNjycPDgxwcHIo9/X81SnrikjGT\nl/z8/ACAX/k2d+7cYnOAIhVHjBgBAAgODsZnn30muv1NmzZpxHZQ8eXLl5g0aZIo6djZ2fHrDtq1\na1eseejt7Q11XLt2TXI/GI6OjkXu8/X1hbm5eUmXr9I9o/GTTz7RCCjKcRw2btwoWiba29vj6tWr\nwLuLlJQVKlSAr68vHx9TNRU5Li4Oa9asEWXZdtOmTQWelg4cOIA1a9bg4MGDAoe0Yiz1VReFjh07\nFlvB9/HxQWFwcXGRJM3GjRsjISGh0P1BQUFgGMagRXUTJkxAnz59UKZMGbi6usLV1RWHDx/Ghg0b\nEBUVhdDQUEydOlVXe6VTFCwsLDB69Gg+VmBKSgrS09MRGxsLjuOQm5srig/F4cOH4+3bt7h06RL6\n9esnaUE2MzPD0aNHkZOTg0WLFqFv3778ikmVh+CFCxcanc64ceP4l//kyZN8SLUyZcrg+++/x8aN\nG7Fx40ZRXh51UVBfMl22bFnMnDkTFy5cQNu2bUXNx4KCEBsbCw8PD8TGxvI1BrGfnaOjIxITE7VO\nHbewsICvry8AgGVZNGrUSC/bo0ePRn5+PnJycpCamiqo1ak+HCzLIjc3F8OGDdPFZukUhZ07d/KZ\nMm7cOJiamsLU1BQmJiZo0KAB0tPTjQpWSkRo2bIl4uPjsXv3bo1YhHZ2dvj8889FLVgeHh5gWRYr\nV67U2Ne2bVvef6Kx6aiLgtSOUwsThY0bN/Lbp02bJlp67u7uGjUD9SaDqknh4eEh6n36+vqCYRjc\nv39fY9+yZcsEofL0tV27dm3cvHkTGRkZAID09HS8ffsW+/fvx+7du+Hj48Pn5bFjx3SxWfpE4eOP\nP0ZmZiaePXuGL774gt8+cuRItGrVCkSEBw8eGC0Kf/75J3bt2qW1oN++fRscx4kSwIToXbPh9u3b\nOHv2LMzMzDT2q15ksUWhefPmICJUrVoVI0eOFDU6syqvtInC06dPJRGFa9euadQStB0jVm3BwsIC\ny5Yt47/YVapUEez/6quv+H0AsHTpUoPTqlKlCrp06QJra2vB9i+++IJ/nqtWrdLFVukShWbNmuHl\ny5dISkoSfAGaN2+O/Px8PH36FESEM2fOGCUKzZs3B8dxWqu2O3bswPnz58FxHPr27StK4ZozZw5Y\nlsU333yjsc/MzAznzp0T7cteUBSqV6+O6OhosCyLuLg4XL58ucgOM32oLgrqgVGys7MlEYWCKKwJ\nJFaHo6qGoK0W0LhxY2RkZPD7jh49KnonY61atfj4lZGRkbo6wy09olC+fHkEBASA4zjew7KKR48e\n5QtZp06dcOHCBaN60Pv164ejR49qbJ8wYQIePHiA5s2bIz09XbR+hqVLlyI3N1drDMLOnTvzwWe0\nBXLRlytXruRFYePGjYiMjNQYgbh79y5q165tdFrqohAZGclvV+8UlkoUpPTyZGFhgQcPHvC1gMzM\nTEH4QDs7Ozx8+JBv4mqL12koW7VqBVdXV9jb2yMsLAws+y5quB7N2dIjCjNmzEBeXp5GR83s2bMF\nhaxLly5GZ3zfvn3h5+cnGNp0dHQU9KBHR0eLFhAmMDAQERERgngLpqamOHz4MP+i/vjjj6IVLHXP\nS69fv+Yd3lpYWGDo0KF8rUGMtBo2bMg/m1OnTsHPz0/wvMT0DanepyCVx2j1JgHHcXjw4AG2bNnC\ndzSq7xPDZ0W1atWwZ88ecBwHAIK8A4DMzEx9+7ekFwUiiiaie0R0V5UgEVUmovNEFPH+r42xonDh\nwgXcvXtXY/uNGzdEF4VGjRohLS0NixYtQosWLTBw4EDBl46IEBMTI1pBW7p0KViWxaBBg/htR44c\nEXy9xRQFFxcXdO3aFV27dtXwa9moUSNRRcHOzo4fJdJGsR3GquDt7Q13d3dcu3YN3t7eotgu2CQo\n+LfgNmP7gD7++GOEhoaCZVlkZGTgwIEDfA0kIyMD69evh1KpRFpaGrp3766r3WIThSoFtq0konnv\nf88jol+NFYWcnBytTis5jkN+fj6vzmKIAtG7sO0RERG891/1TK9Zs6aoPhutra0RExMDjuNw/vx5\nBAcHAwBOnjyJ7du3S+apWhu7desmqigQEXr37l2oMIglCh4eHigKYkxeUolCwdoAx3EaNYUFCxYY\nlVa1atV4QVB1Ip49e5b/v0mTJiB6F6Lu4cOHSEtLw5QpU3Rp9pWYKDwhourvf1cnoifGisKVK1cQ\nHR0tmMAza9Ys5OfnY86cOXyNQSxR+BBjYmL43nsxOHLkSPj7+/MPvXv37jA1NcWGDRtw48YNSUO5\nqejk5MTHQBRTFIjeucrfsmULvLy8JBEFBwcHfi6COry9veHj44PY2FjExsYaLQwDBw7E5s2beU6f\nPh2tW7dG7dq1+RrCH3/8YfT9zJ49W6OvRyU4586dExzr6OiIK1eu8A6Gz58/X1SoumIRhedEdIeI\nbhPRxPfbUgsck2KsKNy6dQscxyE2NhbLli3D5s2bkZycjGvXrvHj+MUlCpUqVUJiYiIqV64sql0T\nExPY2NjAxsaG3xYSEoKQkBDJ74no3VdHVQBDQ0MlS0eq5oODgwM/F6FgR6OLiws/HCn2dGfVBCWW\nZREdHa33BCVtVI0IqTM3NxeTJ0/WOo2/TJkyOHDggGBC09u3b7XZLhZRqPH+b1UiCiOizqSjKBDR\nRCK69Z5FZtK8efP4F1+dVlZWsLe3x927d5GXl6d3hF9D2LRpUzAMUyxpJScnF5soLFmyhC98gwcP\nliwd1bNLSUkRXViJCLGxsVpHH1QdkWL1Mag4cuRIvk+hU6dOoth89uwZn09KpRIXLlzQSUAHDx6M\noKAgZGVlgeM4bccU7+gDEXkR0WySoPlARPj222+RkZGBrKws+Pn58aHOmjZtivz8fFy6dEmygqzO\nFi1aFJbholMqURg+fLgg8rKHhwf/dVq9erWk9/Ts2TMAQEJCgiSh/lTTmgtud3FxASDuVOcFCxbw\nX+cRI0aIZrddu3ZYs2YNvLy8DJpU5uTkhDVr1mjbJ60oEJEFEVmq/b5GRL2IaBUJOxpXiiEKRO+q\n7gULkrOzMziOw6NHjyQtzOoZrlQqiyUtKUShffv2ePv2Lby8vGBubo5NmzbxgpCXlydpLAgi4YxG\nqaJuxcbGatQI1IcsxWhCfPXVV4LRiH/ACkhdKLko1KV3TYYwInpARAveb7cloov0bkjyIhFVFksU\ntFElCleuXCmWjLW1tcWbN28kT6dChQp4+/at6KKgviJSFWBWtSJzxYoVkt/X9OnTeVHYt2+fJGm4\nu7vznYvaFkkZu+DLzs4OAPgmrbbJbv9Qlp7JS0VRJQqLFi0qloxVTYOWOp2ePXvysxmrVq0qqu0N\nGzbwsxpHjx5d0gVVMnp7e+PatWv8akkxbI4cOZJfz5CYmIjGjRuX+H3qwf+OKISFhaF8+fLFkrHF\n1afQokULZGdnS97Gl6kfVcORLMti+vTpJX49elKOECUFnJycKCAggOrUqVPSlyJDhr7QKUKULAoy\nZPx3IIeNkyFDhv6QRUGGDBkCyKIgQ4YMAWRRkCFDhgCyKMgolejYsSNNnz69pC/jX4kyJX0BMv5b\n8PLyojp16lC/fv3o9u3blJCQQEFBQbRz507R0li4cCEtXryYHB0dRbP5X4IsCv9AWFlZ0eLFi6lf\nv35Up04dOnfuHPXu3Vuy9JycnPh0ExMTKSEhQTTbn3/+OfXs2ZMAkJmZGU2ZMkU1YY26detGCoWC\n6tevT48fP6arV68and6MGTNo4cKF9PjxY4qLizPaXknD0tKShgwZQh9//DHVqFGDIiMjKSEhga5d\nu0ZPnjyhN2/eiJ6mPE+hABwcHKhjx47k4uLCb6tWrRqlpKTQiRMn+K+blAgLC6NmzZrxL09SUhLV\nqFFDFNtWVlY0dOhQGjRoEFWpUoWIiFq1asWn5efnRwMHDhQlrR49epCPjw9VqlSJt5+Xl0dRUVF0\n8uRJIiKaOnUqVahQgfz9/al79+5GpTdz5kxaunQpXblyhaZNm0YRERFG30NJY9WqVfTRRx9Ramoq\nERG1adOGmjRpQkREGRkZtGvXLlq1ahXFx8frYk6neQolPsVZ12nOLVq0wG+//cZ7mWFZFr///ju6\ndeuGunXravjE15cmJiZYvXq1IKyayn32mzdv8PjxY94r0ZkzZ0RdKqvimDFjEBYWpuH7T0ef/kXS\nyckJW7duRUJCgsAZR8FoQxcvXhTtfqZMmSKwf/z4cY2VkXv37gXLsnjw4IFRTlf69u2LzMxMxMTE\noE6dOlJNExbQxcUFnTt3RpcuXdC9e3eMHDkSMTEx8PHxESXMX1H8+uuvcfz4cd7bko4+MErX2oeD\nBw/yL0lBR5kMw+DmzZv45JNPDMpgExMTbNy4kXcyMmHCBDg5OcHJyQm2traoXr06bGxs4OLigoSE\nBLAsi6dPn4q2UKlhw4aIiIhAfn4+GIbB8uXL0aFDB5ibm8Pc3Fzg+8AQTp48GUqlUuDFx9fXF99/\n/z1Gjx6N4cOHo3Xr1mjfvr2ohblNmzY4c+YM9uzZw/sVVOeoUaMAvPNSvH//fqPSunfvHnJzcyWJ\nW1m+fHnY2Nhg7NixOH36NM+4uDi8evUKr169QnJyssABUNOmTUW/Dm3s0aMH0tLSkJOTg169en3o\n+NIlCn369AHDMMjJyYG7uzuaNWuGbdu24cSJE7wwZGRkGOQ7sV+/fmBZFmFhYahRo0aRx965c4d/\nue7fv290lOuyZcvizJkzYBgGsbGxokSCUqdCocDly5fBcRzy8vLg4eEhuhdlQ7hgwQKkpKSA4zhk\nZmZi/vz5Bttq0qQJGIbR8F8oFqdOnVqoR+rCePXq1WLLy88//xxZWVnYuXPnh44tXaJgamoKc3Nz\nfPfddxrbO3fujJycHDAMg/bt2+udqf369QPDMBqBZrRRXRRYljWqMBMRpk2bxouamM5gVWzTpg1/\nrWPGjCm2gloYy5cvjxEjRvA1F47jsGPHDqNs7t69GxzHoVu3bpJcc1RUFP+y5+TkIDIyEpGRkZg3\nbx6ePHnC/x8ZGYmcnBxwHIf09HSB236puW/fPqSlpaFu3bpFHVe6RKEojh8/nn+xDBWFnJwcnY4t\nKArJyclGxZU8e/YsGIbBoUOHJPHaPH36dLAsi4cPH6JcuXKCffb29mjVqhVPMaJQfYiqKNrq/Rk6\nhjzTylq1aiE/Px8cx+Gjjz6S5JrVawAfiv59584d/tiCHzApWVhslALUSRRK1ZDksWPH6MGDBwad\na2pqSq6urhQYGKjzOUFBQbR//37Kzc01KM2BAwdSly5dKDs7m1asWEEcxxlkpygMGjSIiIiioqKo\ndu3a1LZtW5o2bRrZ29uTlZUVWVtbk0KhIACUmppKkZGR5OvrS8ePH6fHjx+Lcg3NmzenqVOnUuvW\nral169b89tu3b9P8+fMpMTHRYNsKhYJMTU217rOysuJ/Z2RkGJ2/CQkJtH//fqNsSIEVK1ZQt27d\naOrUqeIYLOlagrE1hZ9//hkMw+DevXsG2yhfvjwOHDjAB/LQFv1ZRfWawqZNm4xSd9VIg4rPnz9H\namoqnj17htDQUEyfPh3Tp0/XGuxWV65du1bDM/DkyZM1oiSr2KNHDyxevBhKpZI/7/2QsUH09PQU\njG6o/3727BlGjBgBCwsLg+1Xr16dD9KyePFi5Obm8te9Y8cOzJo1i2dYWBg4jsPz58/5KOW6UGVP\nl/4e9ZqCyuO4MWWkKM6aNQscx+HZs2cf7At7z9LffKhevToSExMRFRVldGj4smXL8iML9+7dw5gx\nY2BpaSk4pn79+vzQJMuyWqNW6cPly5fj2bNnGnz9+jUACKrZL1++hIuLi94dmx06dMDr169x/vx5\ndO7cWefzHBwcEBAQAJZljXL5XlAUnj17ptF80OcF1cYzZ84IXsQxY8ZoFdKqVatizpw5SEtLw6VL\nl1CmTBmd7KtiKvyTRKFHjx7IysrCw4cPdRUE0H9BFI4fPw6GYbB161ZRMtrJyQlDhw5FZmYmP3Ye\nEhKCpUuXIiQkBK9fvxYUaKmGnerWrYsvvvgCW7duxblz55CXl8fXJgzxgGxnZwczMzM4OTlhy5Yt\nep33559/FhZYRC8OHjyYD3RjaWmJrVu38i+ODr3mRXLkyJGCF7FBgwZFHq8aTfjhhx90sm9qaory\n5cvrJCLGioKrqytWrVqFo0ePIiEhgR/yfPXqFRISEnDq1CkMHDgQWVlZuHfvnr6eqUu/KADA48eP\nYWtra3ShVaetrS1++uknhIaGIj09nQ/JlZCQgNzcXMlFoSA7duzIi0JUVJTBdlxdXcGybKFNB230\n8vLSpQMLRIT4+Hjs378fq1atQvv27bXOTVC/DlVNwdnZ2aj8MTMzQ3JyMoB3cx4iIyPRp0+fQo8v\nU6YMbt68ifPnz4v+rNRFIS8vT29RUBeUW7duoXv37mjdujV+/PFHHDhwAAzD8Pv9/PzQqFEjffyT\nln5RYFkW33//vegPVp1NmzaFu7s7X8CXL19e7KKgUCjQpUsXXhgM9cCsehknT56s8zlbtmz5YI87\nkXDok+PehZ4fOXKk1mNV0ZNZlsX+/ft1rsYXRRcXF6SmpoLjODx8+LDIoTmFQoHg4GDJRcGQ0Ye9\ne/fizZs3AnHYv38/wsPDce7cOeTk5GDv3r0YPXo07t+/D47jcPPmTXh6ehbZF/aepVsUunbtitjY\nWI12v9QcO3ZssYtC2bJlMW7cODAMA6VS+aGx6CIZFhYGADhz5kyhX+iyZcuiRYsWWL16NTiOw/Dh\nwz9ot0aNGmBZFhEREejevbvG8KeKP/zwA7Kzs/k8nDt3rmj59NNPP/EzC+/cuVOo2AwfPhwsy2Li\nxImiPqchQ4YgPT29WIckv/jiC+zZswfx8fF4+/Yt9u3bV1RfV+kVBXt7ezx58sTooB6G8PvvvwfL\nssjKypJsXFyd9erVw6ZNm/hawrZt24yy17VrV77PhGVZ+Pv7IyAgAP7+/jzDw8MFnYO6fMlr1KgB\njuOKnFVYvnx5wRfwxYsXoudXu3bt+C9teHg4lixZwlMVgZphGGzevFn0tGfPni24t08//bTYyqWV\nlRWqVasGFxeXot6L0isKc+bMAcMwxZbh6lQNSV64cEHSdGrUqIFNmzYhNTUVDMMgLy8P27Ztg52d\nndG2u3TpgnPnzvHiUHCBlGrbkydP4OnpqbNd1bnqkbOJCL169cL27dsFi7EePXokWc98gwYN8N13\n32lMPX748CF27dqFqVOnolIyG0kVAAAgAElEQVSlSqKnO3v2bAAo9mnOerB0Tl4qU6YM9ezZk16+\nfFms6Xbp0oU2bNhAdevWlTSdmjVrkqenJ40bN04lmBQdHU0zZ86kEydOiJJGUFAQBQUFUY0aNcjc\n3Jz69u2rccz169fp7t27lJOTo7f906dPk6+vLzVu3Jhat25NLVu25O+FiOjp06c0e/ZsSktLM+o+\nCkNERARFRETQpk2bJLFfFFT3Wbt2bXJ2dqaQkJBivwajUdK1BH1rCj/++KPRvfCG0NPTE/Hx8WBZ\nFklJSZJMCf7777/BMAzWrFmDOnXq/FuClspUY0lNc9aRpbOmoELt2rWLNb3FixdTfn4+DR8+nLy8\nvCRxtCKldyUZMnRGSdcS9K0pdO/eHf7+/pg2bVpJq65MmRrs3bs3/vzzz391TUF2xyZDxn8Hctg4\nGTJk6A9ZFGTIkCGALAoyZMgQQBYFGTJkCPCvFgVvb2+6du0a+fj4kIODQ0lfjgwZpQMlPRyp75Ck\nOlXQc025Xvzoo48wefJkAP9zenL69Okil+bK1OSKFSuQnZ3Nu+Y/efKkKFO2S5q//vorYmNjS/w6\n1Ffvfvvtt4UdJ87aByLaRURJRHRfbVtlIjpPRBHv/9q8364gonVE9IyIwomotVSi4O7uDh8fH0kF\nYcaMGYiOjtaIMcEwDFJSUnDmzJkSLwz/Bk6ePFmQf6rfPXv2LPFrM5a//vorOI4rsfQrV66MgwcP\n4tWrV2AYBg8fPkTlypULO140UehMRK1JKAoriWje+9/ziOjX97/7ENHf9E4cnInouhSi4ODggNjY\nWMkV2tPTkw/Q8vbtW35xkoppaWn44osvSrxgGkIPDw/MnDkTM2fOREBAgKAmpKJq27p16wxKQ6FQ\nwM7Ojl9EVpKiUK5cOVStWhVVq1aFi4sLPD099VrsVRgdHR0RFRWFevXqlchz7Nu3r6BMXrt2rajj\nxVslSUROJBSFJ0RU/f3v6kT05P3vrUQ0TNtxYoqCu7s7AHwoA0ThokWLsGzZMhC9c9e2atUqwUMQ\n0x8A0TvBmz59Os6dOyfwBWls0BkVXVxcsH//fo2aT8H/1bfl5ubCz89P77R69+6t1T7Lsjhx4kSx\nPLsjR47gyJEj8Pf313qfYqTTr18/tGzZUvL70fYsd+3axd9LWFgYHB0dizpHUlFILbA/5f3fk0TU\nUW37RSL6RGxRiI2NBQC4u7sX+4NQd40mpig0btwY48ePR0ZGhsbLyTAMxo0bJ0o6R44c0fpyaBOF\nK1eu4PLlyzh58qTeUaWcnJwQGhqq1X5UVJQkgW8KsiihE1MUiN7VvIqzHE6cOBFv3rwR3Mu+ffs+\ndF6JLIhSaNkGrQcqFBOJaKK+Cbi7u5ODgwPFxcWRj4+PvqcbhU6dOtHBgwf5/xmGofT0dKNs1qtX\njw4ePEj169cna2vrQo9bsGAB7dy50+B0zM3NycvLi9q3by/Yfv/+fVq2bJnWc44ePWpQWnZ2dnTi\nxAlq3Lixxr7Xr1/T7t276d69ewbZ1gcKhYLS09Ppzz//pMqVK1O9evX4GBfZ2dm0Z88eUdKpUKEC\ntWzZUhRbuqB69erk4ODAx7VgGIbi4+PFWyr+b2s+XLt2TWvTwcHBQVJPTM7Oznxnjopr1qwx2J6J\niQlatmyJqKgoja/ZwoULYWtri8zMTH5benq6Lj74CuXgwYM1vpi3bt0SPZ9UfQiFfaH9/f3h5uaG\nhQsX4vfff8fvv/8ONzc3Ua+hQoUK2L59O1JSUvD5559LViZUrFixIn766SfJ01GxYDnUw42ApM2H\nVSTsaFz5/ndfEnY03tDRvk43pepLiI2N5ZsODg4OvFAAgI+PjygZb2FhgeHDh/NUKpWCB+Hl5WWU\nw9Fq1appvDj37t3DxIkT0axZMwQHB4vWhPDw8MDbt28FnYgDBgwQvbA6OTnh/v37Gh2W6p2WBX+r\n/h87dqwo19C0aVOcOnUKDMNg165dkryUBdm2bdticc2nosqlnIpHjhzR9VzRRh8OE9ErIsonohdE\nNI6IbOldf0HE+7+V3x+rIKKNRBRJRPdIh/4EfURB9fJ7e3uD6F1HizYY2tdgamqK2bNnIygoCCEh\nIYW2RU+dOmV0yPb169fz9nJycrB27VreRZh6JG0xRKFgO1qMXndtVO9DKKotr60/Iz093eio0e3b\nt8fVq1d5u19++WWxvKT79++XxL1bQdarVw9BQUH8/cXHx6Nv374a7u+KYOny0agSBPWagPr/qlqE\nMbUFVei4D33pWJbVpae3UKoHxP3mm2809j9//lzjpcrKykLDhg0NSs/NzQ1JSUm8rdu3b+PIkSP4\n8ccfRfXutGHDBoNFgWEYPHr0yOC0Ve7OtT2z5ORkODk5if6S2tnZ4e3bt7z3aI7jsGjRItHTISJs\n3ryZv68XL15g9erVhtgpPaKg/sKragGqbapeXzFEYdGiRXj27BkYhkFmZiYCAwMRGBiI/v37o1mz\nZjh58qSgMN+8eRO1atXSO53u3bsjNzcXDMNg1qxZ6N+/P/r3748ZM2bg/PnzWl8qXQOyFMZ169Zp\nfRGPHz+OLl26iFJwmzRpgqioKIOaDyzLIiEhweChvb/++qvIEZU3b95IEqq+d+/esLa2hqmpKTIz\nM3HgwAHR05gxYwZfXhiGMSaiVukRBW9vb42X3cPDA9euXeNnNIohCqqCPXToUPTv319jn52dHcaO\nHSsoeIYOSV66dKnQr6o2Ll261OjC5eTkhNWrV2P16tUaL6aHhwf69u1rdBqq9rwhNQWGYTB16lSD\n0jUzM8OgQYMwYsQI2NnZoWXLlrhw4QI/tZphGISEhIj+wqozMzPTaBf86ixbtizq1KmD8PBwQX41\nbtzYUJulRxRU8xLUX3YfHx8NkVBB1ecgBa2srEQRhZ49exbaVImPj8fx48exYMECflvVqlVFvY+a\nNWuiT58+gmncGRkZWpsz+nD79u1ITk42SBSysrIKjSplCF1dXTVGQqQqF0TvRGHOnDmi2Vu7dq3g\n2uPj4/mJdAay9IqCg4MDAAhGIFTHxMbGSroeoqAoJCcnG9TpWL58eWzYsAFv374V2Lt06RKqVasG\nov+NULx8+RLW1taS3E+HDh0EL2ZKSgo+++wzo2x27txZL1GYOnUqpk6dqpcgdO7cGd7e3rh37x7P\n+/fvC/4vmI6xTbCi6OrqipycHFFHIQr2LSUmJqJTp07G2Cw9oqBqPgDv+hBUouDh4QEPDw+BIEg5\nV6F69epYunSpKKKgYt26dfHNN99g69at6NWrlyDcmkoUgoODjZqjUBRV96P+Aokxb0AVSUuXPoUu\nXbro3a8RHh6uNYBNYWlmZGRIuj5h5cqVSElJEcWWg4MD/Pz8BLNbfXx8jBUEUGkSBfWaQGEQu4Yw\nZswYLF++HEOGDIG9vT2WL1+uMWnEmOaDLlSJwuHDh/Heua2obNWqldavtxii0L9/f6Snp3+wphAe\nHo6DBw/qPflHlynMLMvi4sWL2L17t+RrE548eYLLly+LYksVXVqdo0aNEsN26Yn7EBcXR7Vr1yYP\nDw9yc3MjFxcXCg4OphcvXlBcXBz9/vvvFBcXJ1p69+7dowYNGlCZMmUoPz+fcnNzydLSUiVgPJRK\nJT18+FC0dAsDy7IaaRuLv/76i7744gv+fxMTE+I4jn755ReDpzerw8/Pj8LDw8nZ2VnrfqVSSeHh\n4TRy5EiKiYnR2767uzs1bdpUsE01hTknJ4d2795NRESpqamUn5+v/w3oiQYNGtBvv/1mtJ2+ffuS\no6Mj/39gYCDFx8fTyZMnjbatM0q6lqBLTaG4qW2egPpXKD4+Hvv378cnn3wi6XWoagqJiYn6TFDR\nSgcHBwwePBh+fn6IiYnR+Ko+evQI8+fPLzRatCF0dHSEl5eXIP9U/Qf/1iXn2tihQwfcvXtXlLxT\nr10xDCO2M5/S03z4r1J9KrSxQ5K1atVCUFAQUlJS8Pz5c8TExOD58+cGzbOQ+a9l6Wk+/FeRkpJC\ngYGB5OrqarStFy9eUJcuXahLly4UFBRk/MXJKLX4VztuLe3Iy8ujxMREIiIKCwsTxaYsCDI+BDls\nnAwZ/x3IYeNkyJChP2RRkCFDhgCyKMiQIUMAWRRkyJAhgCwKMmTIEEAWBRkyZAhQakTh4MGDdP78\n+ZK+DL1haWlJc+fOJZZlBTxy5Ah98803ZGlpWdKX+K/FuXPnyN/fv9jy0MfHh1iWpUmTJhVLepKh\npKc4izXN+fTp01i/fr1oU0KrV6+Opk2b8n4RO3XqhA0bNmDHjh2CpbkrV6402Kvz+vXrcf/+/SI9\nLt27d090ByvqtLKyQqtWrfDbb7/h3LlzyMzMxG+//Waw/8l/EjmOA8dxGDJkiORp+fj48CEGc3Jy\n8Ndff4meRufOnTFw4EB89913WLVqlWCZ+Pr16zF58uQPrb8onWsfli9frtXhSEpKCk6fPm10xru4\nuMDLywtxcXFgGAbZ2dnw9/cvcqmuvtGTbW1tMWPGDGRlZWm1W5DBwcGSFeawsDCt1xAYGAgrKytR\n0jAxMUH58uUxYcIEqGPt2rWwtLSU7N4SEhLw+vVrWFhYSJaGigXz8OzZs6LYHTt2LO7evYu7d+8i\nKSkJ6enpRZaZD3iVLn2iUK1aNXAch4kTJ2rsS0lJQVhYmMGZ/8knn+DkyZPIysoqdG2+UqnEq1ev\n+BgQqm22trZ6pTVjxgwNYYmLi8OePXuwZ88eHD9+XJB2bm6uKP4T1Vm2bFkcOnRIcA0+Pj7Yt28f\nn+7MmTONSsPU1BSWlpbw9PQEy7K8u7I5c+Zg3759yMrKwpgxYyTxFUH0rqbw8OFDSWyrs2LFimBZ\nFqdOnUJUVBQWL14smm+PD63YVTEtLQ07d+5E2bJli7JX+kShW7du4DgO8+bN09jn6+trsCg4ODgg\nISGh0IwPDw+Hm5sbnJ2d0bhxY8TExPDHGBLERN17k7+/P1xdXQW1n7Jly+LXX38VXMuVK1dEKWRl\ny5ZFp06deJfvGRkZmD9/Ppo1awYTExPY2dnxovfjjz8anI6joyP27duHvLw8hIaGYvr06ahZs6bg\nmGbNmiE1NbWo0OlGkeM4LFy4UBLb6pw3bx5fXv7++29RaybaROHnn3/GsmXLBNTR/X/pE4UpU6Yg\nIyNDo3AREQ4ePGiwKFSvXl0j6k5ycjLWr1+P1q1b81Wy+vXrCx7SsWPHDCoATk5OCA8PLzJGwMcf\nf4zExES+7yIhIUEU/39ffvklf/0ZGRlo3bq1YH/ZsmUxYcIEDB06FBUqVNDbvqmpKSZOnIj79+/j\nxYsXRXpU6tChAzIzMzFixAjRXiJ1chyntayIzXXr1gk+IobG59DGkSNHCsqlkQFuSp8oXLx4EdHR\n0Vr3rVmzxqjmQ/369XHz5k2sXr0anTt31tiv7lmZZVkcO3ZMskLWsmVLQaQjlmVx48YNvSM/F+Tk\nyZP5GkJ4eDiGDh0q2N+nTx8EBwcjNTUVTZs21dv+xIkTcfDgQSQlJcHLy+uDx48fPx4sy0oWsYrj\nOMkc3qpTXRTevHmDOnXqiGb7s88+E/hqNNLlW+kSBWtra7x+/RobN27Uun/lypVGiUJhVAUrVf8S\nHDlyRJLOq82bN+PMmTMa1cXs7GxRApmcPXuWFwRV52jFihXRuHFjvHr1ShBwpH379nrb37p1K0aN\nGoX69evrdLyfnx9YlpWk+dC0aVM8f/5ckudUoUIFjB07FtWqVYONjQ127drFl4/ff/9d9PTc3Nxw\n8eJF/tksX74ckyZNMsRW6RKF2bNng+O4QgvQ+vXrRROFypUrw83NDfv27eO/rOqikJKSgoSEBDx+\n/Bienp6iFLwaNWrwMRgK8sKFC6Lcl8rV19OnT7Ft2zZs27ZN495ycnJw5swZSYdBid4Nr2VkZODv\nv/8W1QWciosWLcL27dslufZu3bqBYRi8fv0aDx484PPQ399fspGOChUqYNu2bXj16hVYlkVgYKAh\ndkqPKBw7dgzJyckaguDo6IiGDRviu+++Q3R0NIB3be+kpCRER0cjMzNT74w7cuRIoaMPT548wfr1\n67F+/XoEBAQIjrl27ZrRD/7ixYvIz8/XcF0eEBCg0fY3hDY2NnBxccGaNWswevRorFmzBgMHDuTv\nIywsDFWqVJGkUKuzSpUqiImJwatXr/QeudGVSUlJaNeunaT30bhxY8GclXXr1kmed0QkaKroeW7p\nEIXWrVsjOzsbW7duxaBBg7BixQps2bIFYWFh/OQUFTMyMuDl5cV3DBoyLOTt7Y3s7GxkZ2fzQUVW\nr16N5s2baxxbuXJlvmnBsqwoD9zNzQ137txBamqqQJB8fX0lGdM/fvw4ACA+Pt7gaN36cu7cuWBZ\nVm+37vowKSnJ4EllurJx48aCZ7R27dpiyT8A/BCvns280iEKS5YsEbz4LMsiMjISBw4cwPz589Gg\nQQNYWVnBx8dHtOZD27Zt0bZtW52OHTx4MF8wxHzwX331FS8Mqi/Dli1bRE2jYsWKYBgGSqVS0iA6\n6qxatSqioqJw+vRpg0Y3dGVSUhIfaUsqlpQoPH36lE93z549KF++vK7nlg5RqFSpEjp27MizsJfV\nmCFJQ9mqVSukpKTwnYFi2585c6ZAFP7++29R7a9YsQIMwxRbDYGoeGoJRO9EQep7GTRokEAUxBx1\nKIqTJ08WNG31qBGXDlHQla9evcL58+eL5aFYW1vD1dVVoNg//PCDUTadnJwwe/ZszJ49m99mZmaG\nhIQESURhwIAByMnJQWJiYrHkmYqZmZmIjY01enj1QywOUfD19eWf/65du2BqaloseXjs2DHBEKUe\n09H/W6KQmpqK5cuXS/5ApkyZgsjISMEX3N/f/0NzzotkwbiLXbt2hb29Pdq3b4+MjAwA79qQZ86c\nEe0+VCHwjImDaQhZloWrq6vk6RS3KPz888/Fkn+VKlXiy112dja+/vprfc7/78R9cHJyovLly9OT\nJ08kse/g4ED9+vWj/v37U48ePfjteXl5dPbsWRo2bBhlZ2cbbL9NmzYqcSQi4peAP3r0iMzMzIjj\nOHUBNQpVqlSh7du3k42NDRERZWZmGm1TV9SoUYPi4uIoIiJC0nTq169PFSpUkDSNgkhOThbdppWV\nFVlZWdHr16/58vXxxx/z+1evXk379u0TPd0SryWIUVM4ceIEUlNTRe1ttrKywuDBg3H69GlBFV7F\nJ0+e6NwZ+SH2799f6/wE9fZqamoqBg4caHRa06ZN4+3u3r27WL5uKs6dO7dYaglDhw6FUqmUPJ1h\nw4ZJ0sms4rx583D//n0+WraXlxeio6P5slhwRqoO/O80H8LCwnDz5k3RHsbYsWPx5s0bjRdTqVTC\nz88Pzs7Oola7zczM0Lx5c6xatQo3btzQEAWlUokBAwYYnU6dOnUE/SCBgYFGNXv0YY0aNfD06dMP\nreIThUOHDsXdu3clT8fGxgb+/v7IysoSfSTFysoKmZmZyMnJwaZNm/D27VveX8Pjx4/RqFEjQ/JS\nHFEgol1ElERE99W2eRHRSyK6+5591PbNJ6JnRPSEiHoWV5+CmKxcuTLCwsL4/oImTZqU+DWJwWXL\nlvGCsG7dOkl9GaizXbt2UCqVos3M/K/w448/xuvXr/lnNn36dAwePNgYm6KJQmciak2aojBby7FN\niCiMiMoTUR0iiiQi03+bKMgUl87OzmBZVjTHIzINpjgdjQAuKRQKpw8d9x4DiOj/AOQS0XOFQvGM\niNoRUbCO58sohQgJCSFTU9OSvgwZOsIYx61TFQpFuEKh2KVQKGzeb6tJRHFqx7x4v02GDBn/Ehgq\nCpuJqB4RtSKiV0Tk/X67Qsux0GZAoVBMVCgUtxQKxS0Dr0GGDBkSwCBRAJAIgAXAEdF2etdEIHpX\nM3BQO7QWEcUXYmMbgE+gQxRcGTJkFB8MEgWFQlFd7d+BRHT//W8/IhqqUCjKKxSKOkTUgIhuGHeJ\nMmTIKE58sKNRoVAcJiJXIqqiUCheEJEnEbkqFIpW9K5pEE1Ek4iIADxQKBQ+RPSQiBgimgKAlebS\nZciQIQlKeuLSv2FI0svLCwDg5eVVLDPyZMqUiP+dGY1SMiAgAIVBTIEwNzfnxUcqb0Tq7NWrl2iO\nYf6J1PbcAgICEBAQoJNT2VJKWRTEoKurK19D0FbQxBIGlbMWlmURHR2NZs2aSXpfVapUKbWiUJSQ\nS/HsHB0dcfXqVcTFxWHWrFmSOo8hereG5OzZswgODtbX5bssClLQ1dVVo3AZa9PW1hYBAQGC5dgv\nXrwQJc5DYTQzM8O9e/ckzSsLCwtMmjQJx44dw/Xr18FxHAAIPGkxDIPDhw/D2dlZsufj5eVVqFAY\nm978+fMRHR3NewVjWdbY2AxFslevXoL8y8nJ0cd/Z+kWhQ4dOvAFLCUlBZ988omkBVydqmq+WAXL\nxcVFsPBK9fvt27eih4tTsW3btnj9+rVg27hx40SrWn/99ddIT0/nC29WVhZevnyJvXv34uXLlwgL\nC4Ovry/i4+PBcRyUSiW/GtBQFnzxC+5X1frEeHa1a9eGj48PcnNzwbIsWrVqhQMHDoBlWXh4eEjy\nzMaPH4/MzExwHIcnT57wfkrHjBmjq43SJwoNGjSAj48P/P39oVQqERgYiDt37uD+/fvw8/ODiYmJ\nJA+jYMH6UOHTlz4+PvxXZvPmzfxvjuPg5uYmyX3MnTsXHMcJtv3111+YM2eO0bZtbW2RlpYGjuMQ\nFRWFefPmFVrrMTExwfLly5Gbm4vGjRsbnGbBZ1KUuKkfa0haTZs2RUxMDFiWRWhoKP+lHjBgAFiW\nxd69e9G0aVP4+Pigf//+ojwvX19fZGRkgOM4zJ8/H05OTli+fDk4jkNqaqquPjZLlygMHz5cUEVj\nWRbJycl4/fo1Dh48CJZltXpcFpsFvzTGflltbW352JSqdfnqtQapRCEkJASPHz/m/7exsUFaWpoo\notCvXz++huDk5PTB4ydOnIiTJ08anF7BJkNAQMAHzzFUFD799FNER0cjOzsbEyZMgJmZGb+vbt26\nePnyJeLi4ni/B6tWrTI6P62trZGQkAClUomgoCD+ealqDRzH6VqjLF2isHDhQnAch5MnT+LixYtQ\nKpVISkrC7du3ERkZCZZlkZGRgUaNGknyEqmoLgpiVLU/++wzge8Eov+JglRxEXr27Im0tDRBNCNV\nx6NYNYXU1FRwHIc2bdp88HhLS0uDo0QZ2sdjqCjExcWBZVmtEZrq1q2LoKAg/qN16tQpo5bdKxQK\nuLu74+rVq+A4Dn5+fiB654X7xo0bgr6F/6Qo3L17FxcvXuS9K1WqVAkWFhYoU6YMqlWrxgdjldq5\nhrooiNF7re4mnGEY7N+/n/8dExMjyT388ccfyMvLw2effcZvE1MUiN6FwOM4DtHR0ViyZAlq1qyJ\nAQMGYOvWrYiKikJSUhKGDRtmdDoFoeszMVQUTpw4AZZl8euvv6J58+aoU6cO3NzccOPGDT6QT3Z2\nNlasWCGoRRhCd3d3/qW/e/cu77J+7dq1AkGIiopCgwYNdLFZekShWbNmyM3NLdR92M6dO5GXlweW\nZZGSkiLJi6SiuiiIYc/S0hKhoaGCfgTV7/T0dLRs2VL0e+A4TiNQaUFR6NSpk1Hu5kxMTLBjxw7+\nnnJzczWC9+jRQaaV+vQjiPUMHR0d8fz5c768qZiWlgaWZZGTkyNKwNy6deuCYRhwHIc7d+4IalKq\n7SrqEUKu9IhCxYoVkZaWhuTkZKxbtw5Dhw7FqFGjcPbsWbAsi4cPH+Lnn38Gy7LF2nwQy6alpSWc\nnZ2xY8cOODs748cff+T7FB49eiRaE6Ju3brIzMzErl27NOI31qpViy/goaGh+PzzzyXJv2fPniEn\nJwc9e/bU2Fe2bFl4e3vrZKdgs0GfazD0vKKoEnMbGxujbbVt2xaXL18Gx3FYv34934E+ZcoUfuRB\nXRT0iBJVekSBiPDtt99qdDTGx8fjxIkTcHR0RFRUlOQxDMQeiiyM5ubmePHiBT88uWPHDlHsTpky\nBSzLYuzYsYLtAwYMwJUrV3gHsT169JDs3jiOw/Xr1wu9b11rD+q1BF06FqV+hgBEqSEQES5dugSO\n4/D06VPUqVMHVatWxdGjR5Geng6lUgknJyfs3r1bFgWid72wffv2xe7du7F48WJ+XLtHjx7Iz88v\nNEy9GCxYmPQpiIZQ1SZXCWCtWrWMtqnqJOvYsSNsbW3RqFEj3L9/HxzH4c2bN2BZFg8ePJDsnipV\nqgSO40Tpt1CHIc0GQLwZjbVr10ZCQoLRfQhE7yaVhYSEgOM4zJs3D7Vq1eInfmVnZ2PatGkg+l/H\n+39eFApjaGgo4uPjYW5uLklhLliYAOlqCer08/PjOx3FcCe/e/dusCyLp0+fIioqihecn3/+GfXr\n10dQUJCkovD999+L5tHZkGehXrsQc/3D+vXr9Q3KUii/+OILjb4X1cxF9WFbKUXhXx8MplKlSlSl\nShW6ffs2ZWVlGWTD1dWVPD09ydXVlQIDAykoKIi6dOlCrq6uWo/v2rWrEVesO9SDpri7u9PNmzeN\nsjdz5kyqVKkSVatWjQBQcHAwjRgxgt+fkpJCdnZ2RqVRGMqUKUOrVq2i+fPnU35+viRpFAZXV1cK\nCAgQbAsMDBTFdpkyZahNmzZ04sQJUewVhnr16tHLly/5/y9fvkx5eXlUrlw58RMr6VqCsTWFGTNm\ngGVZtGjRwmAb2moChaE4l057e3vzNQUxJsF8iH/++SceP34sSWyGevXqgeM4KBSKIo/TdVaqOgpr\nykm9iI3oXTgAMReWFawpXL9+HdbW1lrzRTWNXOyagjGOW/8R6N+/P2VmZlJSUpKk6SxevJgUCoVo\nXxhtWLRoEQUGBpKDgwM5ODiQpaUlKRQKUigUpFQqJUtXHQ0aNKC2bduKbvfChQtERKqPQKEYMmSI\nTvbUn4Orqyt5eXkJCD/Pr00AABsuSURBVIACAgIEtb3AwEDq2rWrqM+wSZMmRER08uRJ+vLLL422\nd/HiRapfvz5Nnz6d6tevT7169aLU1FTiOM5o2zqjpGsJxtQUypYti/DwcKOmyKqobbGMau19cdQO\nbG1t8erVK8GCKPXfYnQ0foh//vknWJbF9OnTRbVrbm6O7OxsZGVlffDYiRMn6vy89IFUPhRmzZrF\nz8UYMmSI5M9InVLVFEpcEIwRBdUc+169ehXrw5CC6v4UCorChg0bNOYVSMGePXtCqVRi+/btotr1\n9PQEx3G4du3aB4+1sLDQ2W5hzYOCoi5lnp07dw4syyIyMrJYQuKpUxYFLXz48CFOnTpVrA9Cpn6s\nX78+srKykJeXJ7nzkZJgxYoV8fLlS3z66afFnnarVq0QEBCA6tWr63pO6RcFjuPQu3fvEi8YMgtn\np06dwHEc8vLySvxaZP5HhiQNHYaUUTy4fPkymZj86/uz/1P4V4uCXNhkyBAf8lslQ4YMAWRRkCFD\nhgCyKMiQIUMAWRT+gWBZliIiIqhhw4YlfSky/sHo3LkzAaBRo0aJalcWhX8QypQpQ05OTsRxHPXr\n14+ePHlS0pf0r0ZoaCjFxMRQ9erVP3ywkQBALMvS3r17ydzcXPL0iIjat29PUVFR4i/GKuk5CsbM\nU/Dy8kJKSgq/eCQvLw/9+vUzyFaDBg2wYsUKhISEIDU1VeDMpSBnzZqFGjVqiD6O7O/vj/z8fDg6\nOko2Vn3t2jWN+wkLC5PkfkqSXbt2xYoVK1CpUiXJ0/L09BTMRGUYRtJZtjY2NggODkZaWhrs7Oz0\nObd0T14yMzPTWHP+6tUrg8KtdejQgV93oCtv3bqFqlWrivagO3bsiBcvXiA/P1/SAvzll1+id+/e\ncHJywuDBg3lfg6GhobC3t5f8BVLxxo0bCA8PF8V5a0Ha29vj6dOnOq+jMIZNmjRBUlISLwpKpRK3\nbt3CypUrJUtz9OjRSEtLM2QKd+kWBfXYAupMT0+Hu7u7XrYmTJggeOFTUlKwZ88eAY8cOaIhDGKF\nddu9ezcAgGVZ3L59W/KCrM6PPvqI91Asltu3wlilShXs27cPGRkZfB6K5T1anc2bNy+WOJl2dnZ8\nzA6WZZGVlYUpU6aAiIyOdlUUU1NT8ccffxhybukVhTlz5uDNmze8EDx48EAgDBcvXtTLnr29PU6f\nPo2HDx+ia9euWkPQlStXDtu2bZNEFHbt2sW7Bv/+++8lL8wFuWTJEklFwdzcHM7OzrzfyYSEBNy8\neRO3b9/G8+fPcejQIaxbtw5WVlaipLd06VLJRcHOzg7+/v6CxWsrVqyQ/FlVqlQJERERvLt3PVk6\nRaFcuXL86rCoqCh8++23sLa2Rl5ensGioCt/+uknSUVh9erVkheqgmzVqhVf/f3uu+9Et1+mTBnM\nnTuXz7ODBw9iyJAhgvB4Kp47d85oYXB1dYVSqZR8rUXv3r0FfQi5ubnFslp30qRJxqz3KZ2i4Ofn\nx7/8Xbp04beriwLDMDpFJtKH48ePR1ZWluii4OzszHdsdu7cWfJCVZDh4eFgWRZXrlwRPRpVq1at\n4OXlBZZlkZeXh7Vr18LJyQlRUVFgGAbp6em4desWfvnlF6SnpyMzMxODBg0yKs0ff/wRLMvir7/+\nkizP7O3tERwcLBCFunXrSv6sypcvb2yk8NInCp06dRK8/Or71LdzHCeKo1MVbWxsNL5q//d//yeK\no1hXV1fk5+cjKChIo0pYpUoVDBgwQLJCZmlpCZZlERISgipVqohqu127dkhISADLsoiNjUX37t1B\n9M4pSXJyMkaPHq1xzpEjR7Ru14fbt29Hamoq+vTpI1m+zZw5UyAIqnB/UnPAgAHIyckxxkbpEgUr\nKyucP39e4N1Wfb9UomBjY4NLly4JBEGpVKJbt25G21Z9RVmWFUS/unTpEgDw+x48eIAxY8agY8eO\nBqfl4OCAhQsXok+fPnBzc8PevXuRlJSE69evixLARJ2nTp3iR3P279+Pdu3a8fs+++yzQgP2eHp6\nGv2FT0hIQFhYmKj3o057e3s8evRIIAgbNmyQLD0VzczM8ODBA1y4cMEYO6VLFFSh01U8e/asYH9e\nXh4AiCoKERERfHtbxYSEBNHajp6ensjPz0d+fj527drFb1fFJFTtUzE+Pt6gMHJlypTBkydPtA6t\nnjp1ClOnThWt6TB06FC+4+3LL7/UWXCqVKnCdz4amnabNm2gVCpx+fJlWFhYYMmSJfo4INHpGh88\neKCRh/Xq1cPPP/+MZcuW8WzZsqUocSBUnDFjBjiOw+LFi9GzZ09Dm8fiiAIRORBRABE9IqIHRDT9\n/fbKRHSeiCLe/7V5v11BROuI6BkRhRNRa2NF4Y8//hAIwsyZMzWOkaKmkJKS8sH5CocOHTLY/ujR\no5GZmSkQhRkzZiA/Px+LFy9GzZo1QUQYNGgQLxTPnj0zKC1TU1NYW1vD2toalpaWIHrXk92+fXuc\nOHECWVlZyMnJMUocWJZFXFwchg8frtd59evXR3h4OG7dumXUXIng4GCwLItx48bhs88+w+HDh8Gy\nLJKTk0V5QWfMmKHRbNDmT7MgHz9+DCcnJ4PTHThwIHJycnD58mV4eHjAzc0NW7Zs0TeOJEhEUahO\n719sIrIkoqdE1ISIVhLRvPfb5xHRr+9/9yGiv+mdODgT0XVjRMHe3h4RERFFioIqpJyKMTExqF27\nttGF4Msvv9SoKRQkwzDYtWsX/6Lpy8jISIEoqGoP6seo+h2MEYUP0cXFBVeuXDGqw/HMmTN6u9of\nMGAAH5jGw8PDqHsIDg5GRkYGH5ncxMQECxYsAMuy6N+/v9F5tHPnzkJf/Nu3byMwMBBubm5wc3PD\nqVOnBPt/++03g9Pt0qWLhpexunXrQqlUIjs7W5+yLk3zgYiOE1F3InpCRNXVhOPJ+99biWiY2vH8\ncYaIQrt27QQvfG5uLkxNTQXH/PDDD4JjxHLWaWVlhb59+/IPWsVRo0bh7du3/IvKsqw+zjMFdHV1\nBcuyuHz5MpydncGyrEZnm+oYAIiMjBTl3rTR1tYWSqUSCxYsMOj85cuX63ysl5cXdu7cifz8fOTm\n5mLx4sVGfU2J3omCUqkUzDStVq0aYmJikJycbFRnauXKlfmJSup8+fKl1qHk9evXiyYKK1asQFpa\nmiB/OnTogPz8fISHh+vj1Fd8USAiJyKKJaJKRJRaYF/K+78niaij2vaLRPSJmKKgvt/Z2RlKpRIc\nxwEAcnNzBUOVhlI13h0VFVXoMY8fP+ZFITg42KB0rK2tcerUKbAsi/v37yM/P18jBJmbmxsvQBMm\nTDD63oqil5cX8vPzMW7cOL3P3bp16wdHZAYPHoxDhw7x06v/+OMPDB06VJQZgOrNB/XtqvklQ4cO\nNdj2nDlzNATh/PnzaNCggeA4CwsLbN26Fa9fvxYca8yktHv37ml0MM6bNw8cx2HLli362BJXFIio\nIhHdJqKv3v9fmCicIk1RaKPF3kQiuvWehd5IQVHIy8sTLAIp2AEZGhpqdOHq2bMnkpOTwbJsoaLg\n4OCAmJgYo0WB6F0V2tfXl+9Q9PX1BdE7wfD09ERycjLy8/Nx+/ZtSRdLEf0vJP2mTZv0Plc1OWnY\nsGE8vb29ERwczFOVX1evXkX79u1RsWJF0a5dZX/z5s38NvV5EW5ubgbbXrt2rYYoXLlyhb/+5s2b\n84JX8Lhnz57B2tra4LTv3buHu3fv8i7kJ02aBIZhcP36dZQvX14fW+KJAhGVJaKzROShrVlAEjYf\nGjVqhLdv32rtUxgyZAgyMjL47YmJiaK42g4KCuIL7/Pnz1GhQgWev//+O/bt24ebN28K+hYuXbpk\nVJoVK1bE1atXeWF4/vw5YmJi+P/v3bsn+uQibTRGFAob4cjPz0d6ejrS09MxadIkVK1aVa/4Drpy\nzpw5yMvLQ3JyMnr37o2OHTsKamHG2FaJwvnz5wXNiKioKDx58gRv3rzR2tfg6+uLhg0bGpX277//\nDo7jcODAASxZsoQXJAcHB31tidbRqCCifUT0e4Htq0jY0bjy/e++JOxovKFDGkXejCosu3pH4t9/\n/81Pd1ZxyZIlohQudVHQhaGhoaIsPe7ZsydfY2BZFq9evYKvry9mzpwp2gKbo0eP4u7du7h//75g\nvkCFChXQt29fKJVKsCyLX375RW/b3bt3x7hx4zT41VdfiXLtulB9aTjHcbyw169f3yi7lSpV4nv+\nv/32W8TFxX1w9GH58uWiBIixsLDA3LlzkZiYiOfPn2P27NmG2hJNFDq+NxhORHffsw8R2dK7pkHE\n+7+V1URkIxFFEtE9+kB/gi6iYG5ujsOHD2tdFanipk2bRFtQs3nzZrx8+VInMZgwYcK/yhfBDz/8\ngLi4OLAsi9zcXJw4cQInTpzAlStX+Ps6fvy4waMpJU1ra2uMHz8eMTExCAwMhIeHh2izNU1MTPiR\njWbNmmHp0qV834FKFF6/fo1p06bBwsJCo0P8H0CdREHx/qUsUbyPRFwkypUrR3PmzCFzc3MKDQ2l\nNm3aUK1atejFixe0ceNGevnyJYl5L+3bt6fRo0fTpEmTNPZt2bKF7ty5Q0ePHqW0tDTR0iwuVKtW\njcaOHUuOjo40YcIEwb7R/9/e2cc2dZ1h/Dkag7abpfEh1hQsQqtEqGkloNXkqyFQVWBLifhqY7VS\nWVIhTaWsAVJUdf1IkagqkdSUrp0mWEEqyYodZVDCH2mZEIgkLt8NkEJKOiAeJC1QxJI4FIL97A/7\n3t7r2I7ta3Pt7PykV9e+vr739fE9j99zfM55y8rw2Wefob+/3yLvJBnkOMnHhzsoZ0RBIpGYJiFR\nkGs0SiQSA1IUJBKJASkKEonEgBQFiURiQIqCRCIxIEVBIpEYkKIgkUgMSFGQZBy73Y7W1ta0Di6T\nZI6cFIVRo0ahsrIS69evR1FRkcFWrFiBpqYm+P1+PPnkk1a7mhCKokBRFEt9mDBhAk6ePIne3l48\n9thjaTuvoihYvXo1HA4HSCIYDCIQCCAYDKKmpiZt17Ga1tZW3LlzBxs2bLDk+sXFxdi1axeCwSDK\nysrMnSzRqdOZNCQ5hnvixIkxJ6Ho9506dSojY8jz8/O5dOlSejwezps3j4qiUFGUlM83HD6fj/X1\n9UlnvlKtoqKC165d4/PPPx/zGLfbrc0jefHFF9NWVm63W5spqZ81qW49Hg8dDofp6zidTpaWltLp\ndLK1tZUul0ubEBUMBk1Nm07E1Htuw4YNGb1ONFMX/VEXFY6zTP7IWrhVb1OmTNGm6Q63Vl46C99u\nt/Pdd9/l5cuXo14z1dySTqdTM/21nE4nFUVhZWWlJhDJnnvlypVaZd++fXvM4+rr6zMiCh6PhyS1\n5dbUWYz6CltTU2PqGpWVlUPEJlKAWlpaMloxrRKFJUuWaOUbCASGW8xl5IlCYWEh33//fQ4MDAwb\nKXz55ZdsampKW+FXV1fzypUrUa+rPm9sbMzIF6+Kgs/nS/q96irAtbW1cRc0yZQo6CMFILRegzoj\nU1+JU12fUa0QkVv1s+gFKJ3fSX5+Prdu3cru7m4C1oiCoijs7e0lSfr9flZUVGizOGPYyBKFd955\nh9euXYsbFbS1tfHDDz/k6tWrOWbMmLSlIS8pKTFMmfb5fDx06BDXrFlDm81Gm83GTZs2pf3Gs9vt\nrK+vJ0l6vd5UFtXQRMHv98d9fyZEweVyaRU1MnxXFIVdXV2mQ/xoEcLg4KC2nubTTz9tEKV0WEVF\nhXYvLFiwQPMjEAjcVVGora3VFvhJMLPWyBKF9vZ27QZSrb29nadPn+Yrr7zCxYsXp73Q1cre19en\niU55eXnUYxVF4e7du9N2bbvdTp/PR5J0uVwpn0cVhWAwGDfblCoK6Up0o1aUwcFBtrS0cPLkyUNe\nj+xvSCXE93g8dLvd9Pl8dLvdcY/zer1R/UjGKioq2NnZqf0QqU3GGzdu3LVIYerUqYa1RJJYt3Pk\niML06dPZ29s7JDIwsQLNsDZ9+nQ2NDRo19q4cWPchUc2bdpkum2sN1UQvF6vqfMsWLCAP/74Y8J9\nCoODg3zuuedM++/xeDQR93g8MY+LDPFT7bAdrrNSXSk71b6FBx54QMtTqd4Tmzdv1lZS/vzzz++a\nKKhrUR4/fjzZRYpHjiiMHj2aZ86cGSIKt2/f5nfffce3337b1MKY0czlciXcYVlSUsK+vr6Y6dCS\nNbXJYCZC0FtzczODwSCvX7/OTz/9NGqzKt3NB30UEK/C1tTUGML+eL/2Zi3VvoW5c+fy6NGjhiZr\nc3OzIcGMKgp79uzJmP+qJdipGM1GjigA4I4dO9jR0WFYIFMvEj09PayqqtKyKpmxkpIS7Qbq7++P\nm3rMZrNxy5YtDAQCaVnCTFEUer1e04lR9DZx4kS2trZqlb69vZ3Lly9ncXExi4uL+cILLxgWxzUj\nCoqiaH0JwWBw2F/m0tJSQ6QQL6pIR2VKpW9BrfD6e25gYIDd3d3s7u6m2+025JfMlP+KorC2tpZd\nXV2cMmXKcJ2K0Sz3RWHu3Ln0+/3s6OjguHHjhrw+e/Zsulwunj17VlNPkmxqakqlwPjoo49qbcPh\nQs3x48ezoaFBS0//8ssvp/xlO51Oer1e+ny+tIpBpN1///184okn2NDQQJ/PR5/Px+bmZq5YsYIH\nDhxIiyjomw2xPouiKCwtLdWESi8Kmfj8Ho+HFy9eTFkUli9fzgsXLrCnp4e3bt3iiRMn2NnZyZ6e\nHi2Rrj6q9Pv9fO+999K2zuWyZctI/pQn1cS5clsU8vPztahguDBp9OjRnDNnDvfu3at9QfrcEImY\nzWbjwYMHDb8IAwMDnDlz5pBj58yZYzi2sbEx5VyFTqeTKpkUhEgrKCgwJDJJR/NBUZRhK1/kMfpt\ndXV1Wj9jpPD4fL6UB0rl5eWxoKBAa8OPHz9eK8P169fzyJEjQ6KJefPmmf4MNptN60Pw+/18/fXX\nzZwvt0WhvLxcK+RE/6p66aWXtC/k1VdfTarA1JA3EAjw0qVL9Pl87O/v58cff6wdc99993HdunU8\nduyY1rR46623Uv6SFEXROhT1pDpy0YypokAyZVFwOp1ROw3tdruh+RI5eCmdow4VRaHb7abH4xki\nPOkYORnL5s+fbxCFq1ev8pFHHjF1ziVLlnDXrl1m+hAiLbdFYeHChVohr1q1KqEPrReFqqqqpAqs\no6NDu576t5XD4dASsCxdupStra3al37mzBlTN5namahGCPoxBGT6OhmT8UettPv370/pHKWlpYZK\n2NXVRbfbrSW5iTbMWT+uIJm/C0nGFJfIwUtmIoRETS8KfX19nDVrlqnzjR07lk1NTQwGg/ziiy9S\n7UOItNwWhaKiIq2Qe3t7uWPHjrgfeNKkSVrq8VREQX3f3r17hyTsLCwsNLQZDx48yKKiIlMVkAz9\n3RgtKlDxer2m5lQkY5s3b9Yq0g8//JBSDo3ISCFeRdV3LKZSYWOJS7Rhzqo4AdCaaJWVlWlvrrW1\ntTEQCCXxMXsuNalwMBhMS27UsOW2KIwbN86Qe1AtoJ07d/Kjjz7iwoULec8997CoqIjl5eU8d+6c\nYZhrsn0Kqij09fUxLy+PlZWVrK6uZldXl9a3UVdXx2nTppnuQBpuclO0ZoX6HtXSLRbTpk3Tmg/B\nYDDh6ExvkZFCvIra0tKS6Ci8mGUYOSJyOAHSb1taWtIuCl999VVaOhpnzJjBq1evmk5FGMVyWxTU\nyqHOc4g2rPnw4cNR5z5cvHgx6SHOBw4cGCJA+ueFhYXp/oLimt1up8vlotfrZSTqrMl0Xq+goIA3\nb940JQrRhi5HRgXprIgOh0Mbyhxt+8wzzxjmWahClGxTJVF78803DfdpkhmhCYT+ATt//vxwsx1T\ntdwXBQBcu3Ytq6qqeOHChSGiEPn8zp07PHHiREpzHmbNmqVNeFLPfePGDW7bti3j026zxerq6rRf\n2FREAQhVVP2ApOrqaq2iWv35Mm3Lli0z3JepTMjbv38/9+3bx7Kyskz4ODJEQbWHHnqIa9asiSoK\nN2/e5L59+/jBBx+YSsRaWFhIh8OhmZl+g1y0uro6U5HC/7vde++93LNnj3ZfppLw2O/3J90floSN\nrFySEonENDJtnEQiSR4pChKJxIAUBYlEYkCKgkQiMTDKagfCXAPgD29ziQmQPmeaXPMXyF6fpyRy\nUFb8+wAAQohjifSMZhPS58yTa/4CuemzHtl8kEgkBqQoSCQSA9kkClusdiAFpM+ZJ9f8BXLTZ42s\n6VOQSCTZQTZFChKJJAuwXBSEEL8XQnwjhPhWCPGa1f7EQghxUQhxWgjRJoQ4Ft43TgjxLyFEZ3g7\n1mIftwkhrggh2nX7ovooQvwlXO6nhBAzs8jndUKIy+GybhNCPKV77c9hn78RQvzOIp/tQoj9Qoiz\nQoivhRCrwvuzuqwTxuLZkT8D8G8ADwIYDeAkgIetnrUZw9eLACZE7KsG8Fr48WsANljs42wAMwG0\nD+cjgKcANAEQABwADmeRz+sArI1y7MPhe2QMgKnhe+dnFvicB2Bm+LENwLmwb1ld1oma1ZHCbwB8\nS/I8ydsA3AAWWexTMiwC8En48ScAFlvoC0geBHA9YncsHxcB2M4QhwD8SgiRd3c8/YkYPsdiEQA3\nyVskLwD4FqF76K5CsofkifDjPgBnAUxClpd1olgtCpMA/Ef3/FJ4XzZCAHuFEMeFEH8M7/s1yR4g\ndKMAmGiZd7GJ5WO2l/2fwqH2Nl2zLOt8FkLkA5gB4DByt6wNWC0KIsq+bP075LckZwIoBrBSCDHb\naodMks1l/zcADwGYDqAHgCu8P6t8FkL8EsA/Aawm2Rvv0Cj7sqWsh2C1KFwCYNc9nwyg2yJf4kKy\nO7y9AmAXQmHr92oYGN5esc7DmMTyMWvLnuT3JAMkgwD+jp+aCFnjsxDi5wgJwj9I7gzvzrmyjobV\nonAUQIEQYqoQYjSAZwE0WuzTEIQQvxBC2NTHAOYDaEfI17LwYWUAdlvjYVxi+dgI4A/hnnEHgP+q\noa/VRLS3lyBU1kDI52eFEGOEEFMBFAA4YoF/AsBWAGdJbtS9lHNlHRWrezoR6pk9h1BP8htW+xPD\nxwcR6vU+CeBr1U8A4wHsA9AZ3o6z2M8dCIXbgwj9Oi2P5SNCIe1fw+V+GsDjWeRzbdinUwhVqDzd\n8W+Eff4GQLFFPs9CKPw/BaAtbE9le1knanJEo0QiMWB180EikWQZUhQkEokBKQoSicSAFAWJRGJA\nioJEIjEgRUEikRiQoiCRSAxIUZBIJAb+B4JWKRVxglOCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10feecd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(cuda if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gradient of inputs\n",
    "\n",
    "# try with a single input\n",
    "example, example_label = trainset[15] # Get one training example to work with\n",
    "example = example.unsqueeze(0) # Unsqueeze to add extra dimension (nn.Module only accepts batches not single examples)\n",
    "# example = example.to(device)\n",
    "print('Input size: {}'.format(example.size()))\n",
    "\n",
    "\n",
    "# try with a batch of inputs, instead of just one input\n",
    "# dataiter = iter(trainset_loader)\n",
    "# example, example_label = dataiter.next()\n",
    "# print('Input size: {}'.format(example.size()))\n",
    "\n",
    "\n",
    "# IMPORTANT: MAKE SURE YOU TURN ON REQUIRES_GRAD BEFORE COMPUTING OUTPUT\n",
    "print('example.requires_grad = {}'.format(example.requires_grad))\n",
    "example.requires_grad_(True) # tell PyTorch that we want to keep track of gradients w.r.t. inputs\n",
    "print('example.requires_grad = {}'.format(example.requires_grad))\n",
    "\n",
    "output = my_model(example)\n",
    "\n",
    "my_model.zero_grad() # zero out all gradients in model so they don't accumulate\n",
    "dout = torch.ones_like(output, dtype=torch.float)\n",
    "\n",
    "grad = torch.autograd.grad(outputs=output, inputs=example, grad_outputs=dout)\n",
    "\n",
    "print('Shape of gradient of scores w.r.t. input: \\n{}'.format(grad[0].size()))\n",
    "# print('Gradient of scores w.r.t. input: \\n{}'.format(grad[0]))\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# We want derivative of scores (NOT loss) with respect to input\n",
    "# Use torch.autograd.grad() function to obtain gradients of scores w.r.t. input\n",
    "# argument 'outputs': the vector (or scalar) w/ respect to which you want to take derivatives\n",
    "# argument 'inputs' : the vector (or scalar) of variables w.r.t. which you're differentiating\n",
    "# arugment 'grad_outputs': a vector (or scalar) of derivatives of the final output layer w.r.r. \n",
    "# the layer you specify with the 'outputs' argument \n",
    "# So what's going on here, is that you basically choose an arbitrary end point in the graph, \n",
    "# and manually feeding in the derivative of that layer w.r.t. the final output of the network\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most important stuff I've done so far is in the following two code blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(input_img, input_label, model, target, epsilon, num_iters=1000):\n",
    "    '''\n",
    "    Produce an adversarial image utilizing the Fast Gradient Sign method\n",
    "    (more accurately, the Iterative Gradient Sign method), as described \n",
    "    by Carlini and Wagner in https://arxiv.org/abs/1608.04644\n",
    "    Arguments:\n",
    "        - input image: torch tensor\n",
    "        - input label: class label of input image\n",
    "        - model: model used to make predictions\n",
    "        - target class: class to trick the model into predicting\n",
    "        - epsilon: number of \n",
    "        - num_iters: how many times to add a perturbation to image\n",
    "    '''\n",
    "    #  NOTE: you can probably do this in batches. <--------------- do this later\n",
    "    \n",
    "    natural = input_img.clone().unsqueeze(0)\n",
    "    input_img = input_img.clone().unsqueeze(0)\n",
    "    input_img.requires_grad_(True)\n",
    "    \n",
    "    perturbation = torch.zeros_like(input_img)\n",
    "    fooled = False\n",
    "    iteration = 0\n",
    "\n",
    "    while fooled is False and iteration < num_iters:\n",
    "        \n",
    "        output = model(input_img)\n",
    "        model.zero_grad() # zero out all gradients in model so they don't accumulate\n",
    "        dout = torch.zeros_like(output, dtype=torch.float)\n",
    "        dout[0][target] += 1.  # only compute gradient w.r.t. target class\n",
    "        grad = torch.autograd.grad(outputs=output, inputs=input_img, grad_outputs=dout)[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             perturbation.add_(epsilon * torch.sign(grad))\n",
    "#             input_img.add_(epsilon * torch.sign(grad))\n",
    "            perturbation.add_(epsilon * grad)\n",
    "            input_img.add_(epsilon * grad)\n",
    "            \n",
    "            prediction = model(input_img)\n",
    "            prediction = prediction.max(1, keepdim=True)[1][0,0].item()\n",
    "\n",
    "            if prediction == target:\n",
    "                fooled = True\n",
    "            iteration += 1\n",
    "        \n",
    "    print('Number of iterations required: {}'.format(iteration))\n",
    "    perturbation = perturbation.detach()\n",
    "    advsersary = input_img.detach()\n",
    "    \n",
    "    return (natural, perturbation, advsersary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i = np.random.randint(len(testset))\n",
    "i = 401\n",
    "target = 2\n",
    "eps = 1e-3\n",
    "num_iters = 15000\n",
    "\n",
    "t, t_label = testset[i] # Get one training example to work with\n",
    "\n",
    "print('True label: {}'.format(t_label))\n",
    "# print('Target class: {}'.format(target))\n",
    "print('\\n\\n')\n",
    "\n",
    "# natural, pert, adv = FGSM(t, t_label, model, target, eps, num_iters)\n",
    "\n",
    "# nat_pred = model(natural).max(1, keepdim=True)[1][0,0].item()\n",
    "# adv_pred = model(adv).max(1, keepdim=True)[1][0,0].item()\n",
    "# print('Natural image prediction: {}'.format(nat_pred))\n",
    "# print('Adversarial image prediction: {}'.format(adv_pred))\n",
    "# compare_plots(natural, pert, adv)\n",
    "\n",
    "import time\n",
    "begin = time.time()\n",
    "\n",
    "for j in range(10):\n",
    "    if j == t_label:\n",
    "        continue\n",
    "    natural, pert, adv = FGSM(t, t_label, model, j, eps, num_iters)\n",
    "\n",
    "    nat_pred = model(natural).max(1, keepdim=True)[1][0,0].item()\n",
    "    adv_pred = model(adv).max(1, keepdim=True)[1][0,0].item()\n",
    "    print('Natural image prediction: {}'.format(nat_pred))\n",
    "    print('Adversarial image prediction: {}'.format(adv_pred))\n",
    "    compare_plots(natural, pert, adv)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "print('Took {} seconds'.format(time.time() - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plots(natural, perturbation, adversary):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(natural.numpy()[0,0], cmap='binary')\n",
    "    plt.title('Natural Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(perturbation.numpy()[0,0], cmap='binary')\n",
    "    plt.title('Perturbation')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(adversary.numpy()[0,0], cmap='binary')\n",
    "    plt.title('Adversarial Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FGSM_modified(input_img, input_label, model, target, epsilon, num_iters=1000):\n",
    "    '''\n",
    "    Same as above except you iterate over all classes when computing gradients, \n",
    "    instead of just the target class\n",
    "    '''\n",
    "    \n",
    "    #  NOTE: you can probably do this in batches. <--------------- do this later\n",
    "    \n",
    "    natural = input_img.clone().unsqueeze(0)\n",
    "    input_img = input_img.clone().unsqueeze(0)\n",
    "    input_img.requires_grad_(True)\n",
    "    \n",
    "    perturbation = torch.zeros_like(input_img)\n",
    "    fooled = False\n",
    "    iteration = 0\n",
    "\n",
    "    while fooled is False and iteration < num_iters:\n",
    "        \n",
    "        \n",
    "        for c in range(10):\n",
    "            output = model(input_img)\n",
    "            model.zero_grad() # zero out all gradients in model so they don't accumulate\n",
    "            dout = torch.zeros_like(output, dtype=torch.float)\n",
    "            dout[0][c] += 1.  # only compute gradient w.r.t. one class\n",
    "            grad = torch.autograd.grad(outputs=output, inputs=input_img, grad_outputs=dout)[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if c == target:\n",
    "                    perturbation.add_(epsilon * torch.sign(grad))\n",
    "                    input_img.add_(epsilon * torch.sign(grad))\n",
    "                else:\n",
    "                    perturbation.sub_(epsilon * torch.sign(grad))\n",
    "                    input_img.sub_(epsilon * torch.sign(grad))\n",
    "\n",
    "                prediction = model(input_img)\n",
    "                prediction = prediction.max(1, keepdim=True)[1][0,0].item()\n",
    "\n",
    "                if prediction == target:\n",
    "                    fooled = True\n",
    "                iteration += 1\n",
    "        \n",
    "    print('Number of iterations required: {}'.format(iteration))\n",
    "    perturbation = perturbation.detach()\n",
    "    advsersary = input_img.detach()\n",
    "    \n",
    "    return (natural, perturbation, advsersary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = np.random.randint(len(testset))\n",
    "i = 700\n",
    "target = 2\n",
    "eps = 1e-4\n",
    "num_iters = 10000\n",
    "\n",
    "t, t_label = testset[i] # Get one training example to work with\n",
    "\n",
    "print('True label: {}'.format(t_label))\n",
    "print('Target class: {}'.format(target))\n",
    "\n",
    "natural, pert, adv = FGSM_modified(t, t_label, model, target, eps, num_iters)\n",
    "\n",
    "nat_pred = model(natural).max(1, keepdim=True)[1][0,0].item()\n",
    "adv_pred = model(adv).max(1, keepdim=True)[1][0,0].item()\n",
    "print('Natural image prediction: {}'.format(nat_pred))\n",
    "print('Adversarial image prediction: {}'.format(adv_pred))\n",
    "\n",
    "compare_plots(natural, pert, adv)\n",
    "\n",
    "\n",
    "# for j in range(5):\n",
    "#     if j == t_label:\n",
    "#         continue\n",
    "#     print('Target class: {}'.format(j))\n",
    "#     natural, pert, adv = FGSM_modified(t, t_label, model, j, eps)\n",
    "#     print( ((natural - adv).numpy()[0,0]**2).sum() ) \n",
    "    \n",
    "#     compare_plots(natural, pert, adv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros_like(output)\n",
    "a[0][4] += 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how good the model is\n",
    "t, t_label = testset[np.random.randint(len(testset))] # Get one training example to work with\n",
    "t = t.unsqueeze(0) # Unsqueeze to add extra dimension (nn.Module only accepts batches not single examples)\n",
    "pred = model(t)\n",
    "pred = pred.max(1, keepdim=True)[1][0,0]\n",
    "\n",
    "print('True label: {}'.format(t_label))\n",
    "print('Predicted label: {}'.format(pred))\n",
    "plt.imshow(t.numpy()[0,0], cmap='binary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this later when importing learned parameters from existing models\n",
    "\n",
    "my_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(5)  # train 5 epochs should get you to about 97% accuracy\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save the model (model checkpointing)\n",
    "\n",
    "Now we have a model! Obviously we do not want to retrain the model everytime we want to use it. Plus if you are training a super big model, you probably want to save checkpoint periodically so that you can always fall back to the last checkpoint in case something bad happened or you simply want to test models at different training iterations.\n",
    "\n",
    "Model checkpointing is fairly simple in PyTorch. First, we define a helper function that can save a model to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training loop with model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_save(epoch, save_interval, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "        test()\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_save(5, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint('mnist-4690.pth', model, optimizer)\n",
    "# should give you the final model accuracy\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-tune a model\n",
    "\n",
    "Sometimes you want to fine-tune a pretrained model instead of training a model from scratch. For example, if you want to train a model on a new dataset that contains natural images. To achieve the best performance, you can start with a model that's fully trained on ImageNet and fine-tune the model.\n",
    "\n",
    "Finetuning a model in PyTorch is super easy! First, let's find out what we saved in a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's in a state dict?\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the fc layers\n",
    "\n",
    "Now say we want to load the conv layers from the checkpoint and train the fc layers. We can simply load a subset of the state dict with the selected names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(model_state)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pretrained weights in a different model\n",
    "\n",
    "We can even use the pretrained conv layers in a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = SmallNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
