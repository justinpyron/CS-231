{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training an MNIST Classifier\n",
    "=====\n",
    "## Custom Dataset, Model Checkpointing, and Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Dataset\n",
    "PyTorch has many built-in datasets such as MNIST and CIFAR. In this tutorial, we demonstrate how to write your own dataset by implementing a custom MNIST dataset class. Use [this link](https://github.com/myleott/mnist_png/blob/master/mnist_png.tar.gz?raw=true) to download the mnist png dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transform=None,\n",
    "                 preload=False,\n",
    "                 subset=None):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "            - subset: the number of examples from each class to include in dataset\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        for i in range(10):\n",
    "            filenames = glob.glob(osp.join(root, str(i), '*.png'))\n",
    "            \n",
    "            if subset is not None:\n",
    "                assert type(subset) is int, 'argument subset must be of type int'\n",
    "                filenames = filenames[:subset]\n",
    "            \n",
    "            for fn in filenames:\n",
    "                self.filenames.append((fn, i)) # (filename, label) pair\n",
    "                \n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn, label in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = osp.join('mnist_png', 'training', '1', '*.png')\n",
    "print(p)\n",
    "# glob.glob(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Image.open(trainset.filenames[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the MNIST dataset. \n",
    "# transforms.ToTensor() automatically converts PIL images to\n",
    "# torch tensors with range [0, 1]\n",
    "trainset = MNIST(\n",
    "    root='mnist_png/training',\n",
    "    preload=True, \n",
    "    transform=transforms.ToTensor(),\n",
    "    subset = 100\n",
    ")\n",
    "\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "# load the testset\n",
    "testset = MNIST(\n",
    "    root='mnist_png/testing',\n",
    "    preload=True, \n",
    "    transform=transforms.ToTensor(),\n",
    "    subset = 100\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6) tensor(9) tensor(4) tensor(1) tensor(9) tensor(8) tensor(9) tensor(3) tensor(8) tensor(3) tensor(2) tensor(0) tensor(2) tensor(5) tensor(6) tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11469a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is i: 0\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 0,  7,  4,  7,  0,  9,  8,  9,  4,  6,  8,  4,  6,  3,\n",
      "         8,  6,  3,  1,  5,  3,  8,  1,  7,  0,  9,  3,  6,  7,\n",
      "         0,  2,  0,  2,  4,  7,  8,  6,  9,  9,  2,  8,  3,  8,\n",
      "         6,  4,  9,  9,  4,  1,  4,  5,  6,  7,  0,  6,  8,  7,\n",
      "         5,  8,  1,  1,  2,  5,  5,  9])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 1\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 7,  4,  8,  5,  6,  9,  1,  4,  3,  0,  4,  2,  6,  8,\n",
      "         2,  6,  3,  9,  6,  6,  2,  0,  3,  2,  5,  6,  3,  5,\n",
      "         2,  7,  7,  5,  7,  4,  3,  4,  2,  5,  8,  5,  3,  1,\n",
      "         8,  7,  9,  5,  0,  4,  5,  2,  0,  9,  1,  4,  3,  0,\n",
      "         1,  2,  0,  1,  0,  3,  5,  5])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 2\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 5,  9,  4,  5,  6,  9,  3,  2,  8,  0,  9,  2,  5,  6,\n",
      "         2,  8,  6,  6,  7,  2,  2,  7,  2,  8,  2,  3,  6,  9,\n",
      "         4,  9,  0,  0,  4,  0,  2,  5,  2,  7,  6,  3,  2,  2,\n",
      "         5,  6,  4,  4,  3,  8,  9,  5,  9,  4,  9,  5,  5,  7,\n",
      "         0,  7,  8,  1,  9,  8,  5,  9])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 3\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 9,  4,  7,  9,  4,  4,  9,  3,  3,  7,  1,  2,  6,  3,\n",
      "         9,  5,  8,  0,  7,  9,  5,  2,  9,  1,  9,  9,  2,  5,\n",
      "         4,  1,  8,  6,  4,  2,  8,  8,  2,  4,  2,  3,  7,  8,\n",
      "         5,  0,  3,  2,  1,  3,  0,  1,  9,  9,  0,  2,  0,  6,\n",
      "         6,  7,  8,  1,  5,  1,  0,  2])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 4\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 8,  7,  8,  5,  9,  6,  8,  2,  9,  6,  6,  9,  9,  7,\n",
      "         5,  8,  7,  2,  3,  2,  9,  9,  8,  1,  7,  7,  1,  6,\n",
      "         3,  9,  8,  6,  0,  0,  8,  9,  2,  4,  9,  4,  0,  4,\n",
      "         3,  6,  8,  5,  7,  3,  4,  2,  6,  1,  6,  4,  8,  1,\n",
      "         3,  4,  9,  9,  6,  5,  0,  8])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 5\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 6,  8,  1,  9,  9,  8,  0,  6,  8,  0,  7,  8,  6,  9,\n",
      "         7,  0,  2,  5,  1,  6,  3,  5,  7,  5,  8,  3,  5,  8,\n",
      "         3,  1,  4,  7,  5,  8,  2,  4,  2,  7,  1,  8,  7,  1,\n",
      "         8,  6,  5,  4,  6,  0,  8,  7,  1,  0,  0,  1,  1,  1,\n",
      "         0,  3,  7,  1,  5,  4,  2,  9])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 6\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 9,  5,  7,  2,  0,  7,  4,  0,  6,  2,  8,  8,  2,  8,\n",
      "         4,  1,  4,  3,  9,  4,  3,  7,  2,  9,  5,  0,  7,  4,\n",
      "         3,  3,  6,  1,  6,  1,  1,  4,  9,  0,  7,  8,  3,  7,\n",
      "         1,  8,  3,  4,  5,  8,  6,  3,  1,  3,  4,  1,  6,  1,\n",
      "         7,  6,  0,  1,  2,  4,  5,  5])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 7\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 3,  5,  9,  2,  3,  4,  7,  2,  9,  9,  5,  5,  1,  6,\n",
      "         4,  4,  9,  6,  4,  6,  8,  1,  9,  2,  5,  0,  8,  4,\n",
      "         4,  5,  3,  3,  1,  5,  5,  2,  1,  6,  7,  5,  4,  2,\n",
      "         3,  1,  6,  4,  4,  2,  0,  9,  0,  8,  1,  4,  0,  1,\n",
      "         7,  7,  6,  0,  0,  3,  6,  3])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 8\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 7,  2,  6,  9,  4,  9,  3,  1,  1,  1,  8,  5,  1,  1,\n",
      "         5,  0,  1,  9,  1,  6,  7,  2,  8,  7,  4,  6,  0,  2,\n",
      "         0,  3,  3,  9,  9,  3,  8,  5,  4,  1,  2,  8,  2,  8,\n",
      "         5,  7,  3,  1,  1,  7,  1,  4,  8,  3,  6,  3,  6,  4,\n",
      "         6,  0,  9,  0,  7,  4,  5,  6])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 9\n",
      "This is j[0]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 6,  7,  9,  7,  7,  1,  0,  7,  2,  4,  5,  4,  5,  4,\n",
      "         4,  2,  0,  4,  5,  3,  3,  3,  5,  6,  8,  8,  3,  6,\n",
      "         8,  5,  2,  0,  1,  5,  2,  1,  5,  4,  2,  1,  1,  5,\n",
      "         0,  4,  7,  5,  1,  7,  3,  8,  0,  1,  3,  4,  4,  0,\n",
      "         6,  0,  9,  6,  9,  8,  2,  0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 10\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 3,  3,  7,  4,  9,  1,  7,  4,  7,  3,  4,  7,  4,  0,\n",
      "         6,  7,  9,  8,  1,  2,  8,  3,  2,  9,  5,  0,  5,  7,\n",
      "         0,  1,  6,  4,  8,  3,  5,  0,  0,  3,  9,  2,  9,  3,\n",
      "         2,  9,  0,  2,  6,  1,  4,  9,  6,  5,  4,  2,  1,  5,\n",
      "         0,  4,  5,  6,  0,  3,  7,  2])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 11\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 8,  4,  2,  0,  7,  7,  5,  9,  0,  6,  7,  1,  2,  5,\n",
      "         7,  2,  6,  1,  2,  0,  7,  7,  7,  2,  6,  9,  7,  3,\n",
      "         4,  1,  8,  0,  9,  7,  6,  3,  3,  1,  1,  6,  8,  0,\n",
      "         3,  0,  3,  5,  4,  6,  8,  3,  1,  1,  5,  5,  3,  0,\n",
      "         2,  3,  4,  5,  6,  4,  9,  4])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 12\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 3,  2,  7,  1,  9,  0,  7,  4,  6,  0,  3,  8,  9,  8,\n",
      "         1,  2,  3,  3,  6,  4,  5,  7,  9,  9,  0,  7,  0,  5,\n",
      "         8,  8,  2,  0,  1,  7,  4,  3,  7,  1,  7,  3,  9,  3,\n",
      "         1,  4,  5,  4,  5,  2,  1,  6,  0,  3,  8,  3,  8,  0,\n",
      "         8,  7,  0,  1,  6,  0,  0,  3])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 13\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 7,  0,  2,  9,  2,  5,  9,  5,  2,  7,  5,  0,  2,  0,\n",
      "         0,  5,  9,  4,  1,  8,  6,  1,  7,  7,  9,  3,  1,  6,\n",
      "         1,  3,  0,  7,  5,  8,  3,  8,  0,  7,  2,  6,  7,  3,\n",
      "         1,  1,  3,  6,  3,  1,  7,  8,  2,  8,  8,  6,  9,  6,\n",
      "         2,  6,  1,  4,  6,  5,  4,  5])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 14\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 4,  8,  4,  6,  1,  5,  9,  7,  9,  8,  3,  9,  7,  2,\n",
      "         6,  3,  3,  5,  2,  9,  8,  6,  6,  8,  6,  8,  8,  0,\n",
      "         3,  0,  9,  2,  1,  2,  7,  2,  9,  8,  8,  8,  3,  4,\n",
      "         8,  2,  5,  2,  0,  8,  0,  6,  2,  7,  4,  1,  4,  7,\n",
      "         5,  1,  2,  8,  7,  8,  4,  2])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is i: 15\n",
      "This is j[0]: \n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])\n",
      "This is j[1]: \n",
      "tensor([ 6,  8,  4,  3,  0,  9,  1,  7,  0,  5,  6,  9,  0,  5,\n",
      "         1,  5,  9,  5,  0,  9,  1,  7,  2,  2,  6,  3,  5,  9,\n",
      "         0,  3,  8,  9,  7,  6,  6,  4,  9,  2,  5,  0])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(trainset_loader):\n",
    "    print('This is i: {}'.format(i))\n",
    "    print('This is j[0]: ')\n",
    "    print(j[0])\n",
    "    print('This is j[1]: ')\n",
    "    print(j[1])\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: torch.Size([64, 1, 28, 28])\n",
      "Label = 0\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXz3CBg1+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11469a400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: torch.Size([64, 1, 28, 28])\n",
      "Label = 5\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11469a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: torch.Size([64, 1, 28, 28])\n",
      "Label = 4\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIrwA0kRfiApwg8kRfiBpAg/kNT/A1B9zvpoDySTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1198b2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainset_loader)\n",
    "\n",
    "for i in range(3):\n",
    "    im, label = dataiter.next()  \n",
    "    # Note: each object returned from dataiter is a tuple:\n",
    "    # first entry is a torch tensor containing all images in the batch\n",
    "    # second entry is a torch tensor containing labels\n",
    "    t = np.squeeze(im.numpy()[0])\n",
    "    print('Shape of data: {}'.format(im.size()))\n",
    "    print('Label = {}'.format(label[0]))\n",
    "    print(t.shape)\n",
    "    plt.imshow(t)\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(cuda if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Conv Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model outputting\n",
    "\n",
    "# Note: the model only will take as input BATCHES of data\n",
    "# So, if you want to input a single example, you'll have to\n",
    "# unsqueeze it, i.e. make it a 4d tensor\n",
    "\n",
    "# get 17th example from dataset\n",
    "t_data, t_label = trainset[17] # this returns (data, label) tuple\n",
    "print('Shape before unsqueeze: {}'.format(t_data.size()))\n",
    "t_data = t_data.unsqueeze(0)\n",
    "print('Shape after unsqueeze: {}'.format(t_data.size()))\n",
    "out = model(t_data)\n",
    "print('Original output: \\n{}'.format(out))\n",
    "print('Numpy output: \\n{}'.format(out.data.numpy()))\n",
    "\n",
    "# To do the same thing but with a batch\n",
    "t_data, t_label = dataiter.next()\n",
    "out = model(t_data)\n",
    "# out = out.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(24*24*5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 24*24*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model, i.e. an instance of the My_net Class\n",
    "my_model = My_net().to(device)\n",
    "\n",
    "# list(my_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([1, 1, 28, 28])\n",
      "example.requires_grad = False\n",
      "example.requires_grad = True\n",
      "\n",
      "Gradients before backward pass\n",
      "bias grad: \n",
      "None\n",
      "example grad: \n",
      "None\n",
      "\n",
      "Gradients after backward pass\n",
      "bias grad: \n",
      "None\n",
      "example grad: \n",
      "None\n",
      "\n",
      "Sample subset of example: \n",
      "tensor([[ 0.9765,  0.9922,  0.9922,  0.7059,  0.2078],\n",
      "        [ 0.9922,  0.9922,  0.7176,  0.1333,  0.0000],\n",
      "        [ 0.9922,  0.5608,  0.0314,  0.0000,  0.0000],\n",
      "        [ 0.3020,  0.0314,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0314,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "output size: \n",
      "torch.Size([1, 10])\n",
      "output: \n",
      "tensor([[ 0.0108,  0.1957,  0.1336,  0.0000,  0.1991,  0.2597,  0.0000,\n",
      "          0.0000,  0.0000,  0.2549]])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[[ 0.0719, -1.1780, -1.1707,  0.3777,  0.7633,  0.2111, -0.6541,\n",
      "            1.1035,  1.3890,  1.0141, -0.0121,  0.2766,  0.0636,  0.2591,\n",
      "           -1.5805, -1.7222,  1.2238,  1.0147,  0.0383, -0.9958,  1.2127,\n",
      "            1.3755,  1.7846,  0.6023, -0.1052, -0.4520,  0.5086, -0.1556],\n",
      "          [ 0.1933, -0.3885, -0.7877,  0.3920, -0.4415, -2.8750,  0.1837,\n",
      "            1.5159,  0.9813,  0.8564,  1.7352,  0.2760,  1.0336, -1.0308,\n",
      "            1.4084,  0.1840, -0.3907, -0.1846, -1.3966, -1.5546,  0.5210,\n",
      "           -0.5367, -0.9531, -1.0360,  0.6935, -0.3254, -0.1288,  0.3927],\n",
      "          [ 0.6713, -0.2002, -1.8831, -1.4161,  0.5774,  1.0070, -0.0532,\n",
      "            0.1689,  3.1341,  1.8366, -1.6416,  1.5663,  0.5284,  0.1409,\n",
      "           -0.3305,  0.9373,  1.5885,  0.5293,  1.7212,  0.2503, -0.1215,\n",
      "           -0.9188,  1.5063,  1.3265,  0.1995, -0.3159, -0.4010,  0.1997],\n",
      "          [-1.5041, -0.4923, -0.4213, -1.4034, -1.7816, -0.5577,  0.7362,\n",
      "           -2.4847, -0.7261,  4.3315,  4.8138, -3.0525, -0.3238, -0.2790,\n",
      "            0.2617,  1.9266, -4.3429,  0.1923, -0.5443,  1.7369, -3.2870,\n",
      "           -0.1458, -3.3251, -0.4467,  0.0023, -1.2206, -0.0952, -0.6855],\n",
      "          [ 0.0651,  1.2877,  0.4795,  2.6751, -0.2268, -2.6355,  1.7161,\n",
      "           -3.1312, -3.7641, -2.7668, -3.2842,  1.0612,  1.2652, -0.1752,\n",
      "           -1.5406,  3.3840, -0.1367, -0.0051, -0.2618,  0.2459, -1.0064,\n",
      "           -0.0901, -1.5538,  0.7536,  1.1503, -0.0687, -0.1463,  1.4615],\n",
      "          [-0.2690, -2.2504,  0.5327,  0.9518, -1.9186, -0.2266,  3.7942,\n",
      "            0.8360,  0.9956,  0.5031, -0.7673, -1.9829, -0.9917,  0.3868,\n",
      "            1.6031, -2.4687, -4.3863, -3.0229,  2.4979, -1.2729,  0.2510,\n",
      "           -3.2252,  1.9879,  2.3050, -0.6219, -0.2930, -1.2092, -0.8675],\n",
      "          [-0.1250, -0.8924,  1.2860,  2.8518, -0.6836, -1.6559,  0.8634,\n",
      "            2.2421, -0.6827, -2.1765, -0.0461,  1.0653, -1.2433, -2.3721,\n",
      "            2.5204,  3.3567,  3.2968, -2.5940,  1.0494,  1.6921,  2.7336,\n",
      "           -3.3278, -2.5430,  2.4321, -0.5403,  0.8212, -0.2535, -0.6537],\n",
      "          [ 0.2621,  0.9674, -1.7251, -0.1314,  1.9993,  1.0294, -2.5919,\n",
      "           -5.1631,  3.2928,  2.0517, -1.9789,  1.2870,  1.6727,  0.2429,\n",
      "           -0.8844, -1.6234, -2.0860,  3.2850, -0.1813, -1.2130, -3.0035,\n",
      "            0.0528,  0.9790, -2.4639, -1.7084,  1.0286,  2.1793, -0.5742],\n",
      "          [-0.5201, -0.9686, -0.8747, -0.0857,  0.7933,  2.2614,  0.2795,\n",
      "            1.9202,  1.0859,  0.5050,  3.3522, -0.7290,  6.1032,  0.0248,\n",
      "           -2.5076,  1.6240,  1.8727,  6.3899, -4.3453,  0.3942,  2.1972,\n",
      "            3.9324,  1.0878,  1.9595, -1.6592,  0.6890, -1.8660, -0.9018],\n",
      "          [-0.7967, -0.3739, -0.8534,  2.9375,  2.5133,  0.1831, -1.2614,\n",
      "           -3.6620,  1.2507, -0.1411,  0.8026,  3.6247,  2.4295, -4.1415,\n",
      "           -1.8408,  4.9913, -2.2704,  8.1390, -0.1339,  1.2496, -2.5394,\n",
      "           -1.2946, -1.5488, -0.5606,  1.9754,  1.3719,  0.3422, -1.0606],\n",
      "          [-1.0080, -1.5359,  3.5366, -1.2794, -0.1865,  0.5596,  5.6790,\n",
      "            1.8349, -1.0237, -1.5638,  2.2363, -0.4257,  0.6873,  2.9635,\n",
      "            3.0249, -2.8596,  1.9696,  5.9252,  3.6483,  1.1292, -0.5477,\n",
      "            3.9882, -2.4610,  2.5563,  1.6989,  2.8628,  0.8073,  1.5413],\n",
      "          [-0.8688,  0.4508,  2.7334,  2.0760,  0.0457, -0.1255, -0.3063,\n",
      "            5.1893,  4.8495,  2.0237, -1.3268,  0.0218,  2.8211,  0.7861,\n",
      "            4.0730, -2.1674,  1.5823,  0.3152,  1.2809,  0.5582,  4.8842,\n",
      "            5.5748,  1.4657, -0.7376, -0.0858, -0.5349,  0.4483, -0.1047],\n",
      "          [-0.4124, -0.5113,  0.2450, -1.2685,  1.2231, -5.0558,  0.7654,\n",
      "            4.1861,  2.7768,  1.0698,  0.6567, -0.3509,  0.9336,  1.1274,\n",
      "           -0.2179,  4.6918, -2.1317, -2.2447, -1.4347, -4.4568,  4.8790,\n",
      "            3.8695,  1.5329, -2.2025, -1.9987,  0.1672, -0.8403, -0.1648],\n",
      "          [ 1.1654, -1.4998,  1.8131,  3.9223,  2.4747, -0.2511,  1.9382,\n",
      "            3.2722, -0.2338,  2.2544, -0.6712,  5.5355,  6.2548, -1.4581,\n",
      "            1.1661, -0.5536,  1.3821, -1.4307,  5.1796,  2.9468, -0.7796,\n",
      "            2.9779,  3.5104, -2.7436, -1.7385,  1.4947,  1.5164,  0.2926],\n",
      "          [ 1.1389,  2.1574,  0.5453, -1.4929,  0.3593,  4.2271,  4.0500,\n",
      "           -0.2136,  3.6596,  2.2275, -0.6908, -0.6405, -0.1913, -0.1717,\n",
      "           -0.2179,  1.9398, -2.4016, -0.5036, -0.8840,  4.6503,  3.6690,\n",
      "           -4.6119,  1.8864,  5.2857,  1.4591, -0.6679,  0.8310,  0.8752],\n",
      "          [-0.7317, -0.6518,  0.0632,  0.6850, -3.4217,  1.3246, -0.1855,\n",
      "            0.2074,  0.9375, -1.6184,  1.4054,  1.4329,  2.5739, -0.6934,\n",
      "           -0.1896,  1.2755, -2.0268, -5.9007,  0.9136,  0.1999, -0.9240,\n",
      "            0.0009, -3.6634, -6.3593, -0.2089,  0.2933, -1.4088, -0.9801],\n",
      "          [-0.7401,  1.9827,  0.2551,  2.6324, -1.3420,  6.3032, -2.5477,\n",
      "           -0.6498, -3.5742,  3.5512,  1.3368,  0.4491,  2.3700,  1.9484,\n",
      "           -1.9606,  5.2977, -0.7675, -1.4458, -0.7546, -2.5657, -1.0655,\n",
      "           -0.5858,  5.4583,  3.4444, -0.2087,  1.3290, -0.4865,  0.0193],\n",
      "          [-1.2163, -0.0274,  2.2156,  2.7133,  2.3422,  1.5638,  2.6966,\n",
      "            6.9535, -1.5967,  2.8959, -1.1229,  4.2222, -3.8800,  0.9588,\n",
      "            5.1977, -0.7285, -0.6588,  1.3249,  2.7359, -1.5282,  1.6237,\n",
      "           -3.8618,  3.3884, -0.9874, -2.3165, -0.9710,  0.6218,  0.9124],\n",
      "          [-0.0853, -1.1352,  4.4261,  1.2980,  0.8034, -3.2132, -5.0991,\n",
      "            3.0643,  0.3966, -3.5723,  2.8183, -1.8395,  0.7881, -1.9835,\n",
      "           -1.2070, -2.4043,  0.5977,  2.2412,  2.1419, -1.6632, -2.2680,\n",
      "            3.5345, -2.3931,  3.3370,  0.4554, -0.6598, -2.5012,  0.3949],\n",
      "          [ 1.6352,  0.1745,  1.0252, -0.1734, -2.8715,  4.8652,  1.1581,\n",
      "            2.2538, -3.2262,  0.2873,  1.7069,  0.1972,  1.5067,  2.0894,\n",
      "            0.5560, -4.0305, -0.5114,  2.4274,  3.4064,  0.7395, -8.4066,\n",
      "           -0.4658, -2.2005,  1.8198, -2.0220,  3.1653, -1.7096, -2.1094],\n",
      "          [ 0.6189, -1.4786, -0.6762,  0.9156,  0.5869,  2.0293,  3.7089,\n",
      "            7.0001,  0.8769,  0.3207,  0.1843,  3.5186, -3.1084, -0.0431,\n",
      "           -0.8506, -0.5138,  0.5909, -2.4160, -0.2879, -2.7665,  3.6743,\n",
      "            0.4806, -1.4447,  1.3931,  1.6251,  1.7893,  0.8951,  1.1605],\n",
      "          [-0.2495,  2.3754, -1.1522, -2.1732, -2.0734, -0.0258,  3.9416,\n",
      "           -3.7924, -1.3701, -0.3089, -2.8113, -1.6117,  1.0585,  2.4004,\n",
      "           -1.4902, -2.2694, -0.0344, -1.0758,  0.2806, -6.9022,  1.0801,\n",
      "            0.9911, -2.6248, -0.4529,  0.6030,  0.0359, -0.9930, -1.8074],\n",
      "          [ 0.2555, -0.4197,  1.8112, -2.6043,  0.1625, -3.7716,  2.6461,\n",
      "            0.3101,  1.7869,  3.4334, -0.5511, -2.1932,  2.0439,  0.8595,\n",
      "            2.8845,  1.3141, -2.3724, -6.9951,  0.2610,  2.3237,  5.7316,\n",
      "           -3.1573,  0.3659, -0.0308,  1.1216,  0.3855,  0.5627, -0.5892],\n",
      "          [ 1.6759,  2.9361,  1.4235, -0.8995, -0.2179,  5.4081, -1.2592,\n",
      "            1.7698, -1.3938, -1.1267, -1.2647,  2.3546, -5.2934,  6.3682,\n",
      "            1.0069, -1.4511, -0.2408,  2.3772, -1.6095, -0.3210, -1.6611,\n",
      "           -0.3999,  2.5119, -1.8961, -4.3663,  1.4932,  0.6363,  0.2302],\n",
      "          [ 0.2206, -1.1435,  3.2197, -2.3894,  1.0328, -1.8338,  2.9142,\n",
      "           -1.4833, -3.6598, -2.2625,  1.0019,  2.1664, -0.7959, -0.8039,\n",
      "            4.0529,  3.5539,  1.4567, -2.8566,  0.0573,  2.2726,  1.4241,\n",
      "           -0.1132,  0.7766,  2.0348, -3.2348,  0.7415,  0.2840, -0.2372],\n",
      "          [ 0.6211,  2.6576,  0.1661,  0.2186,  1.1378,  0.7566,  0.7364,\n",
      "            0.8356, -2.4987,  0.4478,  0.2538,  0.5401,  2.1219, -0.1876,\n",
      "           -2.3667, -1.5641,  4.4550,  2.4005, -1.3200, -0.0192, -1.0390,\n",
      "            0.4457,  0.7224,  2.9173, -2.1862,  2.3425, -0.7902,  0.0413],\n",
      "          [-1.7000,  0.1057, -1.0932,  0.9365, -0.4652,  0.5913, -0.3645,\n",
      "            1.2305,  0.5593,  2.0923, -0.0239,  2.2690, -0.8309, -1.0877,\n",
      "            1.6150, -1.1397,  1.2985, -0.1937,  2.2188,  0.3807,  0.2192,\n",
      "           -1.0937, -0.3767,  0.5535, -0.6272, -0.4962,  1.1587, -0.4064],\n",
      "          [ 0.0672, -0.3466, -0.9778, -0.3477,  1.0545,  0.6037, -0.2091,\n",
      "            0.4247,  1.5924,  0.0313,  0.5275,  1.6217,  0.6192, -0.8817,\n",
      "            0.2193, -1.4152,  0.4858,  0.0605, -1.6837,  0.8379,  1.7707,\n",
      "           -0.4102, -0.4938, -0.3224, -0.2494, -1.0109,  0.5354,  0.0511]]]])\n"
     ]
    }
   ],
   "source": [
    "# Get gradient of inputs\n",
    "\n",
    "example, example_label = trainset[15] # Get one training example to work with\n",
    "example = example.unsqueeze(0) # Unsqueeze to add extra dimension (nn.Module only accepts batches not single examples)\n",
    "example = example.to(device)\n",
    "print('Input size: {}'.format(example.size()))\n",
    "\n",
    "\n",
    "# IMPORTANT: MAKE SURE YOU TURN ON REQUIRES_GRAD BEFORE COMPUTING OUTPUT\n",
    "print('example.requires_grad = {}'.format(example.requires_grad))\n",
    "example.requires_grad_(True) # tell PyTorch that we want to keep track of gradients w.r.t. inputs\n",
    "print('example.requires_grad = {}'.format(example.requires_grad))\n",
    "\n",
    "output = my_model(example)\n",
    "\n",
    "\n",
    "my_model.zero_grad() # zero out all gradients in model so they don't accumulate\n",
    "dout = torch.ones_like(output, dtype=torch.float)\n",
    "# dout = torch.FloatTensor([1.]*10)\n",
    "\n",
    "print('\\nGradients before backward pass')\n",
    "print('bias grad: \\n{}'.format(my_model.conv1.bias.grad))\n",
    "print('example grad: \\n{}'.format(example.grad))\n",
    "\n",
    "\n",
    "\n",
    "# grad = torch.autograd.grad(outputs=output, inputs=example, grad_outputs=dout, allow_unused=True)\n",
    "# output.backward(gradient=dout)\n",
    "grad = torch.autograd.grad(outputs=output, inputs=example, grad_outputs=dout)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nGradients after backward pass')\n",
    "print('bias grad: \\n{}'.format(my_model.conv1.bias.grad))\n",
    "print('example grad: \\n{}'.format(example.grad))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nSample subset of example: \\n{}'.format(example[0,0,10:15,10:15]) )\n",
    "print('output size: \\n{}'.format(output.size()))\n",
    "print('output: \\n{}'.format(output))\n",
    "\n",
    "\n",
    "print(grad[0].size())\n",
    "print(grad[0])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# We want derivative of scores (NOT loss) with respect to input\n",
    "# Use torch.autograd.grad() function to obtain gradients of scores w.r.t. input\n",
    "# argument 'outputs': the vector (or scalar) w/ respect to which you want to take derivatives\n",
    "# argument 'inputs' : the vector (or scalar) of variables w.r.t. which you're differentiating\n",
    "# arugment 'grad_outputs': a vector (or scalar) of derivatives of the final output layer w.r.r. \n",
    "# the layer you specify with the 'outputs' argument \n",
    "# So what's going on here, is that you basically choose an arbitrary end point in the graph, \n",
    "# and manually feeding in the derivative of that layer w.r.t. the final output of the network\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0108,  0.1957,  0.1336,  0.0000,  0.1991,  0.2597,  0.0000,\n",
      "          0.0000,  0.0000,  0.2549]])\n",
      "tensor([[ 0.0000,  0.4437,  0.3048,  0.0000,  0.3274,  0.5522,  0.0000,\n",
      "          0.0000,  0.0413,  0.5269]])\n"
     ]
    }
   ],
   "source": [
    "# Obviously, example is in fact used when computing output\n",
    "print(my_model(example))\n",
    "print(my_model(example * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.0816,  0.0066, -0.0993,  0.0754, -0.1704],\n",
       "                        [ 0.1466, -0.1454, -0.1590, -0.1264,  0.0906],\n",
       "                        [-0.0739,  0.0748, -0.1697, -0.1213, -0.0734],\n",
       "                        [-0.0393, -0.1526,  0.1310, -0.0472,  0.0642],\n",
       "                        [ 0.1414,  0.0373,  0.0547,  0.1931, -0.0902]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0634, -0.0890,  0.1429,  0.1597, -0.1844],\n",
       "                        [ 0.1707,  0.0955,  0.0872,  0.0823,  0.1663],\n",
       "                        [-0.0264, -0.1691, -0.0574, -0.1409,  0.0132],\n",
       "                        [-0.0373, -0.1073, -0.0182,  0.1895, -0.0158],\n",
       "                        [ 0.0064, -0.0312,  0.0314,  0.1782,  0.1223]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0710,  0.0435,  0.0472,  0.0773, -0.0258],\n",
       "                        [-0.1859, -0.1237,  0.1707,  0.0120, -0.1620],\n",
       "                        [ 0.0315,  0.1653, -0.1890, -0.1346, -0.0797],\n",
       "                        [ 0.0080, -0.0466, -0.0220, -0.1950,  0.0937],\n",
       "                        [ 0.1755,  0.1222, -0.1416, -0.1612,  0.0831]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0045,  0.0820, -0.1954, -0.0119,  0.1410],\n",
       "                        [ 0.0928,  0.0073,  0.0393, -0.0189, -0.1100],\n",
       "                        [-0.0756, -0.1218,  0.1661,  0.1101,  0.0699],\n",
       "                        [-0.1534,  0.1543,  0.0627,  0.1384, -0.0787],\n",
       "                        [ 0.0424,  0.1953,  0.1345,  0.1604, -0.0420]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1524, -0.1566,  0.0173, -0.1126, -0.0466],\n",
       "                        [-0.0512,  0.0150,  0.1820,  0.0990, -0.0008],\n",
       "                        [ 0.1420, -0.1025,  0.1031, -0.0185, -0.0348],\n",
       "                        [ 0.0234, -0.1532,  0.0231,  0.0672,  0.1710],\n",
       "                        [-0.0623,  0.0720,  0.1999, -0.0858,  0.1901]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.0993,  0.0882,  0.0784,  0.0559,  0.1582])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-7.5312e-03,  4.8973e-03,  1.0458e-04,  ..., -2.2979e-03,\n",
       "                        1.9590e-03,  1.6159e-02],\n",
       "                      [-3.5766e-03, -1.6868e-02, -1.2106e-02,  ..., -2.5934e-03,\n",
       "                        9.6020e-03, -1.7382e-02],\n",
       "                      [ 1.2654e-02,  4.1047e-04, -1.2956e-02,  ..., -3.0782e-03,\n",
       "                       -1.1823e-02,  1.4333e-02],\n",
       "                      ...,\n",
       "                      [ 1.1134e-02,  1.1947e-02, -1.7374e-02,  ..., -1.7323e-02,\n",
       "                       -6.0263e-03,  1.5162e-02],\n",
       "                      [-6.6942e-03,  7.8567e-03, -8.9635e-03,  ..., -1.1087e-02,\n",
       "                        1.7403e-02,  6.7972e-03],\n",
       "                      [-3.0773e-03,  8.3501e-03,  5.6197e-03,  ...,  6.2826e-03,\n",
       "                       -2.1340e-03,  2.3864e-03]])),\n",
       "             ('fc1.bias', tensor(1.00000e-02 *\n",
       "                     [-1.6902,  0.3430,  0.0265, -0.4952,  1.6463, -1.5663,  1.1202,\n",
       "                       0.5572, -1.6604, -1.5037]))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(5)  # train 5 epochs should get you to about 97% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save the model (model checkpointing)\n",
    "\n",
    "Now we have a model! Obviously we do not want to retrain the model everytime we want to use it. Plus if you are training a super big model, you probably want to save checkpoint periodically so that you can always fall back to the last checkpoint in case something bad happened or you simply want to test models at different training iterations.\n",
    "\n",
    "Model checkpointing is fairly simple in PyTorch. First, we define a helper function that can save a model to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training loop with model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_save(epoch, save_interval, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "        test()\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_save(5, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint('mnist-4690.pth', model, optimizer)\n",
    "# should give you the final model accuracy\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-tune a model\n",
    "\n",
    "Sometimes you want to fine-tune a pretrained model instead of training a model from scratch. For example, if you want to train a model on a new dataset that contains natural images. To achieve the best performance, you can start with a model that's fully trained on ImageNet and fine-tune the model.\n",
    "\n",
    "Finetuning a model in PyTorch is super easy! First, let's find out what we saved in a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's in a state dict?\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the fc layers\n",
    "\n",
    "Now say we want to load the conv layers from the checkpoint and train the fc layers. We can simply load a subset of the state dict with the selected names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(model_state)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pretrained weights in a different model\n",
    "\n",
    "We can even use the pretrained conv layers in a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = SmallNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('mnist-4690.pth')\n",
    "states_to_load = {}\n",
    "for name, param in checkpoint['state_dict'].items():\n",
    "    if name.startswith('conv'):\n",
    "        states_to_load[name] = param\n",
    "\n",
    "# Construct a new state dict in which the layers we want\n",
    "# to import from the checkpoint is update with the parameters\n",
    "# from the checkpoint\n",
    "model_state = model.state_dict()\n",
    "model_state.update(states_to_load)\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(1)  # training 1 epoch will get you to 93%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
